{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# For my Mac\n",
    "os.chdir('//Users//patricklee//Desktop//파이썬//DACON//2020DACON_CUP')\n",
    "\n",
    "# For my Desktop\n",
    "# os.chdir('C://Users//BIS_COM//data//dacon//2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'./new_train_df.csv', parse_dates=['c_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_time</th>\n",
       "      <th>id</th>\n",
       "      <th>ds_level</th>\n",
       "      <th>country_code</th>\n",
       "      <th>Total visit</th>\n",
       "      <th>browser</th>\n",
       "      <th>platform</th>\n",
       "      <th>Total User</th>\n",
       "      <th>사용자</th>\n",
       "      <th>세션</th>\n",
       "      <th>신규방문자</th>\n",
       "      <th>페이지뷰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-09 01:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-09 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-09 13:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-09 18:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-09 21:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13454</th>\n",
       "      <td>2019-12-30 07:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13455</th>\n",
       "      <td>2019-12-30 08:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13456</th>\n",
       "      <td>2019-12-30 12:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13457</th>\n",
       "      <td>2019-12-30 15:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13458</th>\n",
       "      <td>2019-12-30 20:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>658.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13459 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   c_time    id  ds_level  country_code  Total visit  browser  \\\n",
       "0     2018-09-09 01:00:00   1.0       1.0           1.0        -99.0    -99.0   \n",
       "1     2018-09-09 03:00:00   1.0       1.0           1.0        -99.0    -99.0   \n",
       "2     2018-09-09 13:00:00   3.0       1.0           1.0        -99.0    -99.0   \n",
       "3     2018-09-09 18:00:00   1.0       1.0           1.0        -99.0    -99.0   \n",
       "4     2018-09-09 21:00:00   2.0       1.0           1.0        -99.0    -99.0   \n",
       "...                   ...   ...       ...           ...          ...      ...   \n",
       "13454 2019-12-30 07:00:00 -99.0     -99.0         -99.0          1.0      1.0   \n",
       "13455 2019-12-30 08:00:00 -99.0     -99.0         -99.0          7.0      3.0   \n",
       "13456 2019-12-30 12:00:00 -99.0     -99.0         -99.0         16.0      5.0   \n",
       "13457 2019-12-30 15:00:00 -99.0     -99.0         -99.0         36.0      7.0   \n",
       "13458 2019-12-30 20:00:00 -99.0     -99.0         -99.0         18.0      2.0   \n",
       "\n",
       "       platform  Total User    사용자     세션  신규방문자    페이지뷰  \n",
       "0         -99.0       -99.0   20.0   19.0    9.0   259.0  \n",
       "1         -99.0       -99.0   10.0   10.0    2.0   102.0  \n",
       "2         -99.0       -99.0   20.0   16.0    7.0   131.0  \n",
       "3         -99.0       -99.0   13.0   12.0    2.0    47.0  \n",
       "4         -99.0       -99.0   17.0   17.0    7.0   107.0  \n",
       "...         ...         ...    ...    ...    ...     ...  \n",
       "13454       1.0         1.0   12.0   14.0    3.0    72.0  \n",
       "13455       3.0         6.0   29.0   29.0    5.0   274.0  \n",
       "13456       4.0        16.0   58.0   59.0   18.0   624.0  \n",
       "13457       5.0        34.0  100.0  100.0   28.0  1196.0  \n",
       "13458       5.0        16.0   49.0   53.0   16.0   658.0  \n",
       "\n",
       "[13459 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index(\"c_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ds_level</th>\n",
       "      <th>country_code</th>\n",
       "      <th>Total visit</th>\n",
       "      <th>browser</th>\n",
       "      <th>platform</th>\n",
       "      <th>Total User</th>\n",
       "      <th>사용자</th>\n",
       "      <th>세션</th>\n",
       "      <th>신규방문자</th>\n",
       "      <th>페이지뷰</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-09 01:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-09 03:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-09 13:00:00</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-09 18:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-09 21:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 07:00:00</th>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 08:00:00</th>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 12:00:00</th>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 15:00:00</th>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30 20:00:00</th>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>658.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13459 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  ds_level  country_code  Total visit  browser  \\\n",
       "c_time                                                                    \n",
       "2018-09-09 01:00:00   1.0       1.0           1.0        -99.0    -99.0   \n",
       "2018-09-09 03:00:00   1.0       1.0           1.0        -99.0    -99.0   \n",
       "2018-09-09 13:00:00   3.0       1.0           1.0        -99.0    -99.0   \n",
       "2018-09-09 18:00:00   1.0       1.0           1.0        -99.0    -99.0   \n",
       "2018-09-09 21:00:00   2.0       1.0           1.0        -99.0    -99.0   \n",
       "...                   ...       ...           ...          ...      ...   \n",
       "2019-12-30 07:00:00 -99.0     -99.0         -99.0          1.0      1.0   \n",
       "2019-12-30 08:00:00 -99.0     -99.0         -99.0          7.0      3.0   \n",
       "2019-12-30 12:00:00 -99.0     -99.0         -99.0         16.0      5.0   \n",
       "2019-12-30 15:00:00 -99.0     -99.0         -99.0         36.0      7.0   \n",
       "2019-12-30 20:00:00 -99.0     -99.0         -99.0         18.0      2.0   \n",
       "\n",
       "                     platform  Total User    사용자     세션  신규방문자    페이지뷰  \n",
       "c_time                                                                  \n",
       "2018-09-09 01:00:00     -99.0       -99.0   20.0   19.0    9.0   259.0  \n",
       "2018-09-09 03:00:00     -99.0       -99.0   10.0   10.0    2.0   102.0  \n",
       "2018-09-09 13:00:00     -99.0       -99.0   20.0   16.0    7.0   131.0  \n",
       "2018-09-09 18:00:00     -99.0       -99.0   13.0   12.0    2.0    47.0  \n",
       "2018-09-09 21:00:00     -99.0       -99.0   17.0   17.0    7.0   107.0  \n",
       "...                       ...         ...    ...    ...    ...     ...  \n",
       "2019-12-30 07:00:00       1.0         1.0   12.0   14.0    3.0    72.0  \n",
       "2019-12-30 08:00:00       3.0         6.0   29.0   29.0    5.0   274.0  \n",
       "2019-12-30 12:00:00       4.0        16.0   58.0   59.0   18.0   624.0  \n",
       "2019-12-30 15:00:00       5.0        34.0  100.0  100.0   28.0  1196.0  \n",
       "2019-12-30 20:00:00       5.0        16.0   49.0   53.0   16.0   658.0  \n",
       "\n",
       "[13459 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제 첫 번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 128\n",
    "verbose = 1\n",
    "nb_classes = 4\n",
    "n_hidden = 128\n",
    "validation_split = 0.2\n",
    "\n",
    "rate = 0.2\n",
    "rate_size = int(len(df) * rate)\n",
    "\n",
    "train = df[:-rate_size]\n",
    "test = df[-rate_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'ds_level', 'country_code', 'Total visit', 'browser', 'platform',\n",
      "       'Total User'],\n",
      "      dtype='object') Index(['사용자', '세션', '신규방문자', '페이지뷰'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "x_col = train.columns[:7]\n",
    "y_col = train.columns[7:]\n",
    "print(x_col, y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[x_col]\n",
    "Y_train = train[y_col]\n",
    "X_test = test[x_col]\n",
    "Y_test = test[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10768, 7) (2691, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(nb_classes, input_shape=(7,)\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'SGD',\n",
    "             loss = 'MSE',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.1401 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 677us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 660us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 674us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 645us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 666us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 727us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 716us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 665us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 642us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 668us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 688us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 806us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 752us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 707us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 724us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 769us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 802us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 753us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 744us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 734us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 726us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 743us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 785us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 746us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 781us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 812us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 762us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 805us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 786us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 798us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 738us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 835us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 753us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 692us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 694us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 722us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 743us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 632us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 640us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 624us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 632us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 661us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 643us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 689us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 633us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 640us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 635us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 744us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 732us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 767us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 55/200\n",
      "68/68 [==============================] - 0s 753us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 699us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 633us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 632us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 650us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 628us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 628us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 622us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 620us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 622us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 619us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 632us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 649us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 632us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 639us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 628us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 617us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 617us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 625us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 631us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 619us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 626us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 632us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 648us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 734us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 629us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 635us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 625us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 632us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 625us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 659us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 632us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 635us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 622us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 626us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 642us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 624us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 815us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 770us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 742us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 659us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 629us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 0s 645us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 628us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 630us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 639us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 630us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 626us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 620us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 615us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 617us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 620us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 638us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 655us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 644us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 617us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 619us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 628us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 624us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 630us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 620us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 613us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 641us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 620us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 617us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 625us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 613us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 628us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 622us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 634us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 618us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 625us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 622us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 624us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 624us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 617us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 625us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 626us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 628us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 625us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 624us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 633us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 626us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 622us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 642us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 643us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 633us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 629us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 624us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 636us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 618us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 626us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 613us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 625us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 625us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 630us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 628us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 619us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 633us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 626us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 624us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 622us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 614us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 627us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 620us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 621us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 617us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 628us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 636us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 620us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 623us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 617us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 613us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 645us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe91040b5d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,\n",
    "         batch_size=batch_size, epochs=epochs,\n",
    "         verbose=verbose, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 365us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Test ACC :  0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test ACC : ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두 번째 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(n_hidden, input_shape=(7,),\n",
    "                            activation='relu'))\n",
    "model.add(keras.layers.Dense(n_hidden,\n",
    "                            activation='relu'))\n",
    "model.add(keras.layers.Dense(nb_classes,\n",
    "                            activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 128)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 18,052\n",
      "Trainable params: 18,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'SGD',\n",
    "             loss = 'MSE',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 [==============================] - 0s 2ms/step - loss: nan - accuracy: 0.0089 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 868us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 862us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 867us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 892us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 890us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 873us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 911us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 911us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 881us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 863us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 894us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 868us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 888us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 882us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 911us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 906us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 878us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 912us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 952us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 937us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 918us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 911us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 915us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 890us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 944us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 872us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 885us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 895us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 932us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 906us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 931us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 926us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 917us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 921us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 993us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 949us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 846us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 841us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 834us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 858us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 844us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 846us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 847us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 837us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 826us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 833us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 838us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 831us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 832us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 843us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 839us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 882us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 55/200\n",
      "68/68 [==============================] - 0s 841us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 838us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 833us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 835us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 854us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 850us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 835us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 828us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 829us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 850us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 975us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 900us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 915us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 934us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 953us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 978us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 996us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 905us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 863us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 832us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 901us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 843us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 847us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 853us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 832us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 844us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 828us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 833us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 847us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 850us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 843us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 831us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 822us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 856us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 843us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 841us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 840us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 847us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 822us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 849us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 834us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 856us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 835us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 845us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 941us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 856us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 843us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 828us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 849us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 0s 852us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 841us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 848us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 882us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 844us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 876us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 891us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 860us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 917us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 984us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 991us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 966us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 940us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 848us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 843us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 838us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 831us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 831us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 817us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 834us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 864us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 883us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 858us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 870us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 868us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 854us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 908us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 828us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 844us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 891us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 981us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 986us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 998us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 886us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 857us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 848us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 823us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 844us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 849us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 857us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 902us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 945us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 869us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 847us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 877us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 958us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 872us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 853us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 861us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 908us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 874us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 863us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 852us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 910us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 881us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 950us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 893us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 870us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 886us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 841us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 842us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 867us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 859us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 844us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 857us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 873us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 877us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 849us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 863us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 891us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 971us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 969us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 986us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe91180d3d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,\n",
    "         batch_size=batch_size, epochs=epochs,\n",
    "         verbose=verbose, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 474us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Test ACC :  0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test ACC : ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세 번째 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(n_hidden, input_shape=(7,),\n",
    "                            activation='relu'))\n",
    "model.add(keras.layers.Dense(n_hidden,\n",
    "                            activation='relu'))\n",
    "model.add(keras.layers.Dense(nb_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 128)               1024      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 18,052\n",
      "Trainable params: 18,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'MSE',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 1234363.2500 - accuracy: 0.9922 - val_loss: 4454.0054 - val_accuracy: 0.9935\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 557176.7500 - accuracy: 0.9928 - val_loss: 4128.3950 - val_accuracy: 0.9935\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 965us/step - loss: 550041.6875 - accuracy: 0.9928 - val_loss: 4070.9927 - val_accuracy: 0.9935\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 546864.4375 - accuracy: 0.9928 - val_loss: 3450.4482 - val_accuracy: 0.9935\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 543251.4375 - accuracy: 0.9928 - val_loss: 3468.5078 - val_accuracy: 0.9935\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 539143.3125 - accuracy: 0.9928 - val_loss: 3459.3523 - val_accuracy: 0.9935\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 533700.2500 - accuracy: 0.9928 - val_loss: 3153.0540 - val_accuracy: 0.9935\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 524841.7500 - accuracy: 0.9928 - val_loss: 3820.6895 - val_accuracy: 0.9935\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 515544.0625 - accuracy: 0.9928 - val_loss: 3499.0674 - val_accuracy: 0.9935\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 504691.1250 - accuracy: 0.9928 - val_loss: 3588.8591 - val_accuracy: 0.9935\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 492706.8750 - accuracy: 0.9928 - val_loss: 3587.8770 - val_accuracy: 0.9935\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 480084.1562 - accuracy: 0.9928 - val_loss: 3483.8931 - val_accuracy: 0.9935\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 460347.8750 - accuracy: 0.9928 - val_loss: 3224.5271 - val_accuracy: 0.9935\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 442518.3438 - accuracy: 0.9928 - val_loss: 3450.2390 - val_accuracy: 0.9935\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 427110.6875 - accuracy: 0.9928 - val_loss: 3916.5706 - val_accuracy: 0.9935\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 413865.1562 - accuracy: 0.9928 - val_loss: 2862.7058 - val_accuracy: 0.9935\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 403523.5312 - accuracy: 0.9928 - val_loss: 3235.0388 - val_accuracy: 0.9935\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 396135.0312 - accuracy: 0.9928 - val_loss: 3497.1108 - val_accuracy: 0.9935\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 389570.0000 - accuracy: 0.9863 - val_loss: 3179.5815 - val_accuracy: 0.9935\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 384586.9062 - accuracy: 0.9892 - val_loss: 5556.0728 - val_accuracy: 0.3273\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 383362.4062 - accuracy: 0.9785 - val_loss: 2870.5615 - val_accuracy: 0.9935\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 382179.2500 - accuracy: 0.9928 - val_loss: 3288.2207 - val_accuracy: 0.9935\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 993us/step - loss: 377406.4375 - accuracy: 0.9928 - val_loss: 3152.6978 - val_accuracy: 0.9935\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 376409.4688 - accuracy: 0.9908 - val_loss: 3110.4041 - val_accuracy: 0.9935\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 372612.7500 - accuracy: 0.9928 - val_loss: 2834.2588 - val_accuracy: 0.9935\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 371487.3750 - accuracy: 0.9796 - val_loss: 3082.8975 - val_accuracy: 0.9935\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 369907.1875 - accuracy: 0.9832 - val_loss: 3389.9697 - val_accuracy: 0.9935\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 370969.8750 - accuracy: 0.9853 - val_loss: 2911.9805 - val_accuracy: 0.9935\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 367174.6250 - accuracy: 0.9789 - val_loss: 3916.2246 - val_accuracy: 0.6472\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 368157.0312 - accuracy: 0.9872 - val_loss: 2925.8379 - val_accuracy: 0.9935\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 365845.7812 - accuracy: 0.9869 - val_loss: 3185.5615 - val_accuracy: 0.9935\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 364291.6562 - accuracy: 0.9791 - val_loss: 2948.3757 - val_accuracy: 0.9935\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 363590.4062 - accuracy: 0.9778 - val_loss: 4253.0312 - val_accuracy: 0.4912\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 362309.1875 - accuracy: 0.9713 - val_loss: 2795.2686 - val_accuracy: 0.9935\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 362163.5625 - accuracy: 0.9781 - val_loss: 3477.6084 - val_accuracy: 0.7098\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 360830.0938 - accuracy: 0.9792 - val_loss: 3389.8347 - val_accuracy: 0.7098\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 364891.8750 - accuracy: 0.9831 - val_loss: 3310.3457 - val_accuracy: 0.7219\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 360581.1562 - accuracy: 0.9807 - val_loss: 2837.4907 - val_accuracy: 0.9935\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 936us/step - loss: 360568.6250 - accuracy: 0.9719 - val_loss: 3124.2737 - val_accuracy: 0.9935\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 899us/step - loss: 359332.2500 - accuracy: 0.9705 - val_loss: 3286.3540 - val_accuracy: 0.7219\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 907us/step - loss: 360009.0312 - accuracy: 0.9717 - val_loss: 3796.8137 - val_accuracy: 0.6411\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 910us/step - loss: 358867.9688 - accuracy: 0.9764 - val_loss: 2976.0022 - val_accuracy: 0.9935\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 906us/step - loss: 360164.2188 - accuracy: 0.9872 - val_loss: 3113.9719 - val_accuracy: 0.9935\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 902us/step - loss: 362337.3750 - accuracy: 0.9865 - val_loss: 3078.9424 - val_accuracy: 0.9935\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 958us/step - loss: 356680.0000 - accuracy: 0.9763 - val_loss: 3746.7710 - val_accuracy: 0.6481\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 931us/step - loss: 357442.0938 - accuracy: 0.9668 - val_loss: 2800.9031 - val_accuracy: 0.9935\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 917us/step - loss: 357344.5625 - accuracy: 0.9731 - val_loss: 3525.0752 - val_accuracy: 0.7094\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 983us/step - loss: 358904.8750 - accuracy: 0.9674 - val_loss: 2775.4124 - val_accuracy: 0.9935\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357748.5938 - accuracy: 0.9769 - val_loss: 2812.6770 - val_accuracy: 0.9935\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358549.7500 - accuracy: 0.9759 - val_loss: 3298.8723 - val_accuracy: 0.7219\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 359910.1250 - accuracy: 0.9871 - val_loss: 2908.4578 - val_accuracy: 0.9935\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 907us/step - loss: 357878.5000 - accuracy: 0.9750 - val_loss: 3028.5928 - val_accuracy: 0.9935\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 917us/step - loss: 358235.1250 - accuracy: 0.9883 - val_loss: 3741.6250 - val_accuracy: 0.7089\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 913us/step - loss: 357947.1875 - accuracy: 0.9797 - val_loss: 2901.5708 - val_accuracy: 0.9935\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 922us/step - loss: 358730.8438 - accuracy: 0.9928 - val_loss: 2896.4688 - val_accuracy: 0.9935\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 904us/step - loss: 360754.0625 - accuracy: 0.9894 - val_loss: 3120.1768 - val_accuracy: 0.9935\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 916us/step - loss: 357420.2188 - accuracy: 0.9593 - val_loss: 3002.8157 - val_accuracy: 0.9935\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 910us/step - loss: 359626.9375 - accuracy: 0.9850 - val_loss: 3694.6453 - val_accuracy: 0.7094\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 921us/step - loss: 357512.2188 - accuracy: 0.9885 - val_loss: 2928.2288 - val_accuracy: 0.9935\n",
      "Epoch 60/200\n",
      "68/68 [==============================] - 0s 936us/step - loss: 358554.7188 - accuracy: 0.9928 - val_loss: 2921.4309 - val_accuracy: 0.9935\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 921us/step - loss: 358055.4688 - accuracy: 0.9891 - val_loss: 2745.3931 - val_accuracy: 0.9935\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357102.4062 - accuracy: 0.9806 - val_loss: 2997.3564 - val_accuracy: 0.9935\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 996us/step - loss: 358112.8750 - accuracy: 0.9923 - val_loss: 2858.8550 - val_accuracy: 0.9935\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 359946.8750 - accuracy: 0.9928 - val_loss: 2989.9124 - val_accuracy: 0.9935\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 359468.8438 - accuracy: 0.9921 - val_loss: 3067.2424 - val_accuracy: 0.9935\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358597.3125 - accuracy: 0.9855 - val_loss: 3042.4006 - val_accuracy: 0.9935\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357301.2500 - accuracy: 0.9928 - val_loss: 3017.0864 - val_accuracy: 0.9935\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 359050.0938 - accuracy: 0.9922 - val_loss: 3327.2390 - val_accuracy: 0.9935\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356603.2812 - accuracy: 0.9928 - val_loss: 3119.1123 - val_accuracy: 0.9935\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 927us/step - loss: 361070.7812 - accuracy: 0.9878 - val_loss: 3673.0691 - val_accuracy: 0.7219\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 910us/step - loss: 357555.2812 - accuracy: 0.9904 - val_loss: 3451.8896 - val_accuracy: 0.9935\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 903us/step - loss: 357578.7188 - accuracy: 0.9913 - val_loss: 2861.0596 - val_accuracy: 0.9935\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 915us/step - loss: 358260.1875 - accuracy: 0.9928 - val_loss: 2908.5542 - val_accuracy: 0.9935\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 990us/step - loss: 359269.0625 - accuracy: 0.9863 - val_loss: 3264.7842 - val_accuracy: 0.9935\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 359741.0625 - accuracy: 0.9829 - val_loss: 2938.3127 - val_accuracy: 0.9935\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357071.2812 - accuracy: 0.9928 - val_loss: 3339.6270 - val_accuracy: 0.9935\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 359624.9375 - accuracy: 0.9855 - val_loss: 4031.7373 - val_accuracy: 0.7098\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 926us/step - loss: 357998.4062 - accuracy: 0.9858 - val_loss: 2882.7068 - val_accuracy: 0.9935\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 903us/step - loss: 359592.9375 - accuracy: 0.9928 - val_loss: 3313.0469 - val_accuracy: 0.9935\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 947us/step - loss: 357484.6562 - accuracy: 0.9928 - val_loss: 2950.5298 - val_accuracy: 0.9935\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 983us/step - loss: 360088.6875 - accuracy: 0.9928 - val_loss: 3679.6768 - val_accuracy: 0.9935\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358593.8438 - accuracy: 0.9912 - val_loss: 2824.4006 - val_accuracy: 0.9935\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357403.3750 - accuracy: 0.9928 - val_loss: 3173.3398 - val_accuracy: 0.9935\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 943us/step - loss: 357314.2188 - accuracy: 0.9811 - val_loss: 2976.9290 - val_accuracy: 0.9935\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 912us/step - loss: 357060.2188 - accuracy: 0.9928 - val_loss: 2996.4973 - val_accuracy: 0.9935\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 903us/step - loss: 358521.5000 - accuracy: 0.9928 - val_loss: 3315.7527 - val_accuracy: 0.9935\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 895us/step - loss: 358803.5938 - accuracy: 0.9928 - val_loss: 2848.0842 - val_accuracy: 0.9935\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 900us/step - loss: 360586.1250 - accuracy: 0.9928 - val_loss: 3278.6201 - val_accuracy: 0.9935\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 911us/step - loss: 358088.7188 - accuracy: 0.9928 - val_loss: 2987.4143 - val_accuracy: 0.9935\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 912us/step - loss: 358422.7188 - accuracy: 0.9928 - val_loss: 3151.7756 - val_accuracy: 0.9935\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 897us/step - loss: 358799.7500 - accuracy: 0.9921 - val_loss: 3049.1545 - val_accuracy: 0.9935\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 902us/step - loss: 356810.2500 - accuracy: 0.9928 - val_loss: 3182.0139 - val_accuracy: 0.9935\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 912us/step - loss: 358877.5938 - accuracy: 0.9928 - val_loss: 3292.9136 - val_accuracy: 0.9935\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 897us/step - loss: 358294.9375 - accuracy: 0.9928 - val_loss: 3616.9417 - val_accuracy: 0.9935\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 993us/step - loss: 357056.4375 - accuracy: 0.9906 - val_loss: 3133.2041 - val_accuracy: 0.9935\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357851.0000 - accuracy: 0.9928 - val_loss: 3107.1755 - val_accuracy: 0.9935\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356747.4062 - accuracy: 0.9897 - val_loss: 3172.2930 - val_accuracy: 0.9935\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 927us/step - loss: 357110.1250 - accuracy: 0.9921 - val_loss: 3045.2312 - val_accuracy: 0.9935\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 912us/step - loss: 357781.9375 - accuracy: 0.9925 - val_loss: 3738.3586 - val_accuracy: 0.9935\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 901us/step - loss: 358689.6250 - accuracy: 0.9928 - val_loss: 3311.7944 - val_accuracy: 0.9935\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 886us/step - loss: 363337.0625 - accuracy: 0.9916 - val_loss: 3196.5112 - val_accuracy: 0.9935\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 898us/step - loss: 356579.4062 - accuracy: 0.9909 - val_loss: 3231.4397 - val_accuracy: 0.9935\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356325.0625 - accuracy: 0.9928 - val_loss: 3018.2905 - val_accuracy: 0.9935\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 355698.2500 - accuracy: 0.9927 - val_loss: 3519.3928 - val_accuracy: 0.9935\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357060.9062 - accuracy: 0.9928 - val_loss: 3572.4604 - val_accuracy: 0.9935\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 990us/step - loss: 356914.4688 - accuracy: 0.9928 - val_loss: 3209.9871 - val_accuracy: 0.9935\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 955us/step - loss: 356557.8125 - accuracy: 0.9927 - val_loss: 2900.3401 - val_accuracy: 0.9935\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 0s 996us/step - loss: 357735.6875 - accuracy: 0.9880 - val_loss: 3421.4680 - val_accuracy: 0.9935\n",
      "Epoch 109/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 1ms/step - loss: 357877.5938 - accuracy: 0.9928 - val_loss: 3018.9624 - val_accuracy: 0.9935\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 991us/step - loss: 360250.9375 - accuracy: 0.9928 - val_loss: 3128.4590 - val_accuracy: 0.9935\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 901us/step - loss: 358240.6875 - accuracy: 0.9927 - val_loss: 3310.4404 - val_accuracy: 0.9935\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 894us/step - loss: 356359.6562 - accuracy: 0.9928 - val_loss: 3356.4741 - val_accuracy: 0.9935\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 904us/step - loss: 355954.7188 - accuracy: 0.9928 - val_loss: 3064.1396 - val_accuracy: 0.9935\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 897us/step - loss: 356877.8750 - accuracy: 0.9900 - val_loss: 3153.5774 - val_accuracy: 0.9935\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 890us/step - loss: 357868.6250 - accuracy: 0.9926 - val_loss: 3251.1731 - val_accuracy: 0.9935\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 975us/step - loss: 357515.7500 - accuracy: 0.9928 - val_loss: 3600.3442 - val_accuracy: 0.9935\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358287.4688 - accuracy: 0.9900 - val_loss: 3264.1680 - val_accuracy: 0.9935\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 359515.6250 - accuracy: 0.9884 - val_loss: 3282.5251 - val_accuracy: 0.9935\n",
      "Epoch 119/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358150.0000 - accuracy: 0.9927 - val_loss: 3349.7061 - val_accuracy: 0.9935\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356981.0625 - accuracy: 0.9927 - val_loss: 3392.3887 - val_accuracy: 0.9935\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356961.1875 - accuracy: 0.9927 - val_loss: 3514.0859 - val_accuracy: 0.9935\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357465.2188 - accuracy: 0.9928 - val_loss: 3078.0911 - val_accuracy: 0.9935\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356057.4688 - accuracy: 0.9927 - val_loss: 3222.1345 - val_accuracy: 0.9935\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356130.9062 - accuracy: 0.9927 - val_loss: 3125.6714 - val_accuracy: 0.9935\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357833.7812 - accuracy: 0.9927 - val_loss: 3185.7842 - val_accuracy: 0.9935\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357049.6562 - accuracy: 0.9927 - val_loss: 3489.9329 - val_accuracy: 0.9935\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358095.8438 - accuracy: 0.9928 - val_loss: 3457.4802 - val_accuracy: 0.9935\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356934.6875 - accuracy: 0.9928 - val_loss: 3572.4712 - val_accuracy: 0.9935\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357802.2812 - accuracy: 0.9928 - val_loss: 3256.4404 - val_accuracy: 0.9935\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 973us/step - loss: 356236.5625 - accuracy: 0.9928 - val_loss: 3187.5952 - val_accuracy: 0.9935\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 963us/step - loss: 358348.4062 - accuracy: 0.9926 - val_loss: 3633.4050 - val_accuracy: 0.9935\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 929us/step - loss: 358246.6562 - accuracy: 0.9928 - val_loss: 3567.7410 - val_accuracy: 0.9935\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 925us/step - loss: 359331.6250 - accuracy: 0.9928 - val_loss: 3152.1294 - val_accuracy: 0.9935\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 945us/step - loss: 356695.8438 - accuracy: 0.9928 - val_loss: 3810.4895 - val_accuracy: 0.9935\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 938us/step - loss: 356122.2812 - accuracy: 0.9928 - val_loss: 3915.1384 - val_accuracy: 0.9935\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 922us/step - loss: 355550.2188 - accuracy: 0.9875 - val_loss: 4303.1914 - val_accuracy: 0.7219\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 904us/step - loss: 357181.7500 - accuracy: 0.9901 - val_loss: 3078.2632 - val_accuracy: 0.9935\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 907us/step - loss: 357163.5625 - accuracy: 0.9928 - val_loss: 3153.2434 - val_accuracy: 0.9935\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 906us/step - loss: 356208.3750 - accuracy: 0.9928 - val_loss: 3199.4131 - val_accuracy: 0.9935\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 907us/step - loss: 358397.1250 - accuracy: 0.9927 - val_loss: 3446.6692 - val_accuracy: 0.9935\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 917us/step - loss: 356112.0312 - accuracy: 0.9927 - val_loss: 3102.3799 - val_accuracy: 0.9935\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 900us/step - loss: 358307.6250 - accuracy: 0.9928 - val_loss: 3924.4651 - val_accuracy: 0.9935\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 916us/step - loss: 356100.3125 - accuracy: 0.9927 - val_loss: 3570.6704 - val_accuracy: 0.9935\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 959us/step - loss: 355934.2188 - accuracy: 0.9928 - val_loss: 3302.6296 - val_accuracy: 0.9935\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 939us/step - loss: 357886.0000 - accuracy: 0.9928 - val_loss: 3020.2234 - val_accuracy: 0.9935\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 938us/step - loss: 357243.8125 - accuracy: 0.9885 - val_loss: 3062.8521 - val_accuracy: 0.9935\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 915us/step - loss: 355961.9375 - accuracy: 0.9880 - val_loss: 3652.7676 - val_accuracy: 0.9935\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 924us/step - loss: 357035.6562 - accuracy: 0.9913 - val_loss: 3502.6829 - val_accuracy: 0.9935\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 918us/step - loss: 356371.8125 - accuracy: 0.9928 - val_loss: 3441.6143 - val_accuracy: 0.9935\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 904us/step - loss: 356653.0312 - accuracy: 0.9928 - val_loss: 2959.5825 - val_accuracy: 0.9935\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 932us/step - loss: 357888.9375 - accuracy: 0.9857 - val_loss: 3654.6772 - val_accuracy: 0.9935\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 926us/step - loss: 356394.6875 - accuracy: 0.9928 - val_loss: 3211.7219 - val_accuracy: 0.9935\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 926us/step - loss: 356538.0312 - accuracy: 0.9926 - val_loss: 3939.0957 - val_accuracy: 0.9935\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 911us/step - loss: 356477.4688 - accuracy: 0.9928 - val_loss: 3793.9412 - val_accuracy: 0.9935\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 905us/step - loss: 356137.9375 - accuracy: 0.9926 - val_loss: 3439.7229 - val_accuracy: 0.9935\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 912us/step - loss: 355764.1875 - accuracy: 0.9928 - val_loss: 3204.2688 - val_accuracy: 0.9935\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 931us/step - loss: 356558.8438 - accuracy: 0.9927 - val_loss: 3260.7493 - val_accuracy: 0.9935\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 919us/step - loss: 355888.4062 - accuracy: 0.9928 - val_loss: 3274.2229 - val_accuracy: 0.9935\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 920us/step - loss: 358709.1875 - accuracy: 0.9928 - val_loss: 3354.1201 - val_accuracy: 0.9935\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 939us/step - loss: 357242.5938 - accuracy: 0.9928 - val_loss: 3422.0710 - val_accuracy: 0.9935\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 915us/step - loss: 356635.8750 - accuracy: 0.9927 - val_loss: 3367.8975 - val_accuracy: 0.9935\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 914us/step - loss: 356042.1875 - accuracy: 0.9928 - val_loss: 4008.2925 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 907us/step - loss: 355199.2188 - accuracy: 0.9928 - val_loss: 4248.6299 - val_accuracy: 0.7159\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 922us/step - loss: 356049.3438 - accuracy: 0.9836 - val_loss: 3111.1008 - val_accuracy: 0.9935\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 916us/step - loss: 359916.5312 - accuracy: 0.9882 - val_loss: 3290.1411 - val_accuracy: 0.9935\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 993us/step - loss: 356763.2188 - accuracy: 0.9928 - val_loss: 3897.7476 - val_accuracy: 0.9935\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356266.9688 - accuracy: 0.9928 - val_loss: 3155.5400 - val_accuracy: 0.9935\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357302.5312 - accuracy: 0.9928 - val_loss: 3080.7725 - val_accuracy: 0.9935\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 978us/step - loss: 358320.1250 - accuracy: 0.9928 - val_loss: 3414.0100 - val_accuracy: 0.9935\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 950us/step - loss: 356516.6875 - accuracy: 0.9928 - val_loss: 2981.3999 - val_accuracy: 0.9935\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 942us/step - loss: 356424.8125 - accuracy: 0.9928 - val_loss: 3939.6262 - val_accuracy: 0.9935\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355013.2500 - accuracy: 0.9928 - val_loss: 3154.8684 - val_accuracy: 0.9935\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356516.0938 - accuracy: 0.9928 - val_loss: 3453.9841 - val_accuracy: 0.9935\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 354736.9688 - accuracy: 0.9928 - val_loss: 3104.4490 - val_accuracy: 0.9935\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355668.8438 - accuracy: 0.9927 - val_loss: 3463.6064 - val_accuracy: 0.9935\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 357356.7188 - accuracy: 0.9927 - val_loss: 4119.3281 - val_accuracy: 0.7159\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356073.1875 - accuracy: 0.9914 - val_loss: 3187.8149 - val_accuracy: 0.9935\n",
      "Epoch 178/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356326.8125 - accuracy: 0.9928 - val_loss: 3429.3213 - val_accuracy: 0.9935\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355959.9375 - accuracy: 0.9928 - val_loss: 3077.8101 - val_accuracy: 0.9935\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355875.1250 - accuracy: 0.9926 - val_loss: 3673.7842 - val_accuracy: 0.9935\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 993us/step - loss: 356584.4688 - accuracy: 0.9928 - val_loss: 3058.1904 - val_accuracy: 0.9935\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358387.0625 - accuracy: 0.9904 - val_loss: 3627.9817 - val_accuracy: 0.9935\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356464.6250 - accuracy: 0.9927 - val_loss: 3346.4758 - val_accuracy: 0.9935\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355003.5938 - accuracy: 0.9928 - val_loss: 3148.4585 - val_accuracy: 0.9935\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355223.0625 - accuracy: 0.9928 - val_loss: 3360.3184 - val_accuracy: 0.9935\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358982.4062 - accuracy: 0.9901 - val_loss: 3169.6453 - val_accuracy: 0.9935\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358484.9375 - accuracy: 0.9928 - val_loss: 3203.8196 - val_accuracy: 0.9935\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355595.8438 - accuracy: 0.9928 - val_loss: 3132.4680 - val_accuracy: 0.9935\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358068.2500 - accuracy: 0.9928 - val_loss: 3392.9355 - val_accuracy: 0.9935\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357989.9062 - accuracy: 0.9928 - val_loss: 3047.8062 - val_accuracy: 0.9935\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356233.4688 - accuracy: 0.9928 - val_loss: 3125.6262 - val_accuracy: 0.9935\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356889.5625 - accuracy: 0.9928 - val_loss: 3214.6912 - val_accuracy: 0.9935\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355216.9375 - accuracy: 0.9928 - val_loss: 3523.9919 - val_accuracy: 0.9935\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356598.7500 - accuracy: 0.9902 - val_loss: 3276.0273 - val_accuracy: 0.9935\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 1000us/step - loss: 355685.7500 - accuracy: 0.9919 - val_loss: 3074.5593 - val_accuracy: 0.9935\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 956us/step - loss: 356714.6562 - accuracy: 0.9928 - val_loss: 3629.5171 - val_accuracy: 0.9935\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 918us/step - loss: 355502.9062 - accuracy: 0.9928 - val_loss: 3140.4155 - val_accuracy: 0.9935\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 921us/step - loss: 357717.6250 - accuracy: 0.9928 - val_loss: 3085.9189 - val_accuracy: 0.9935\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355028.2500 - accuracy: 0.9928 - val_loss: 3582.7688 - val_accuracy: 0.9935\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355409.0000 - accuracy: 0.9928 - val_loss: 3307.2231 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8f1db8b10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,\n",
    "         batch_size=batch_size, epochs=epochs,\n",
    "         verbose=verbose, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 405us/step - loss: 12574.5400 - accuracy: 1.0000\n",
      "Test ACC :  1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test ACC : ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'RMSProp',\n",
    "             loss = 'MSE',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 357746.1562 - accuracy: 0.9921 - val_loss: 4086.6621 - val_accuracy: 0.9935\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 939us/step - loss: 358670.9375 - accuracy: 0.9928 - val_loss: 3657.4036 - val_accuracy: 0.9935\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 935us/step - loss: 358037.1875 - accuracy: 0.9928 - val_loss: 3491.0017 - val_accuracy: 0.9935\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 943us/step - loss: 357575.5000 - accuracy: 0.9928 - val_loss: 3537.5002 - val_accuracy: 0.9935\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 943us/step - loss: 357709.0625 - accuracy: 0.9923 - val_loss: 3997.9229 - val_accuracy: 0.9935\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 947us/step - loss: 356073.1250 - accuracy: 0.9916 - val_loss: 4064.8718 - val_accuracy: 0.9935\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 922us/step - loss: 358564.6875 - accuracy: 0.9928 - val_loss: 3407.1074 - val_accuracy: 0.9935\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 852us/step - loss: 358645.7188 - accuracy: 0.9918 - val_loss: 3207.6694 - val_accuracy: 0.9935\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 970us/step - loss: 358035.1562 - accuracy: 0.9920 - val_loss: 3409.7090 - val_accuracy: 0.9935\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357075.0000 - accuracy: 0.9921 - val_loss: 3065.8240 - val_accuracy: 0.9935\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357013.2188 - accuracy: 0.9921 - val_loss: 3789.9084 - val_accuracy: 0.9935\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357160.9375 - accuracy: 0.9928 - val_loss: 3026.7119 - val_accuracy: 0.9935\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 358359.0625 - accuracy: 0.9927 - val_loss: 3623.5664 - val_accuracy: 0.9935\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356350.1562 - accuracy: 0.9928 - val_loss: 3927.2317 - val_accuracy: 0.9935\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357550.0000 - accuracy: 0.9918 - val_loss: 4012.7437 - val_accuracy: 0.9935\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 990us/step - loss: 357936.6250 - accuracy: 0.9928 - val_loss: 2918.3308 - val_accuracy: 0.9935\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 960us/step - loss: 356868.3750 - accuracy: 0.9920 - val_loss: 3194.1824 - val_accuracy: 0.9935\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357371.3438 - accuracy: 0.9920 - val_loss: 3564.0542 - val_accuracy: 0.9935\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 939us/step - loss: 356937.8125 - accuracy: 0.9928 - val_loss: 3051.6953 - val_accuracy: 0.9935\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356766.3750 - accuracy: 0.9928 - val_loss: 3295.5959 - val_accuracy: 0.9935\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 357925.0312 - accuracy: 0.9928 - val_loss: 4022.0129 - val_accuracy: 0.9935\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 985us/step - loss: 357755.1250 - accuracy: 0.9928 - val_loss: 4115.0967 - val_accuracy: 0.9935\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 958us/step - loss: 357487.5938 - accuracy: 0.9922 - val_loss: 3143.2510 - val_accuracy: 0.9935\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 932us/step - loss: 357369.0000 - accuracy: 0.9925 - val_loss: 2978.1746 - val_accuracy: 0.9935\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 906us/step - loss: 357460.7812 - accuracy: 0.9923 - val_loss: 3339.9404 - val_accuracy: 0.9935\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 936us/step - loss: 356731.5000 - accuracy: 0.9915 - val_loss: 4913.1147 - val_accuracy: 0.5279\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 886us/step - loss: 357384.8750 - accuracy: 0.9916 - val_loss: 2921.0408 - val_accuracy: 0.9935\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 876us/step - loss: 358288.0625 - accuracy: 0.9928 - val_loss: 4599.0234 - val_accuracy: 0.7159\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 902us/step - loss: 356346.6875 - accuracy: 0.9919 - val_loss: 4329.3916 - val_accuracy: 0.9935\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 903us/step - loss: 357080.9062 - accuracy: 0.9928 - val_loss: 4066.2173 - val_accuracy: 0.9935\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 887us/step - loss: 357336.1250 - accuracy: 0.9926 - val_loss: 3893.8264 - val_accuracy: 0.9935\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 984us/step - loss: 356959.6875 - accuracy: 0.9923 - val_loss: 3331.1079 - val_accuracy: 0.9935\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 904us/step - loss: 356692.5312 - accuracy: 0.9921 - val_loss: 3853.0125 - val_accuracy: 0.9935\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 915us/step - loss: 357311.5000 - accuracy: 0.9928 - val_loss: 4119.8145 - val_accuracy: 0.7219\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356416.9062 - accuracy: 0.9920 - val_loss: 3592.6519 - val_accuracy: 0.9935\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 917us/step - loss: 356782.7188 - accuracy: 0.9927 - val_loss: 3008.0342 - val_accuracy: 0.9935\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 901us/step - loss: 356330.3125 - accuracy: 0.9920 - val_loss: 3793.8269 - val_accuracy: 0.9935\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 916us/step - loss: 356511.7812 - accuracy: 0.9928 - val_loss: 3577.3989 - val_accuracy: 0.9935\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 866us/step - loss: 356371.0938 - accuracy: 0.9923 - val_loss: 3457.6816 - val_accuracy: 0.9935\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 885us/step - loss: 356163.1250 - accuracy: 0.9928 - val_loss: 2980.8914 - val_accuracy: 0.9935\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 869us/step - loss: 358197.1250 - accuracy: 0.9926 - val_loss: 3435.5093 - val_accuracy: 0.9935\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 929us/step - loss: 356504.2812 - accuracy: 0.9921 - val_loss: 4426.1548 - val_accuracy: 0.7219\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 883us/step - loss: 357611.5000 - accuracy: 0.9898 - val_loss: 2969.5034 - val_accuracy: 0.9935\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 860us/step - loss: 356270.3438 - accuracy: 0.9914 - val_loss: 3533.2834 - val_accuracy: 0.9935\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 869us/step - loss: 357193.6250 - accuracy: 0.9908 - val_loss: 3599.4033 - val_accuracy: 0.9935\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 356947.7500 - accuracy: 0.9928 - val_loss: 3534.0955 - val_accuracy: 0.9935\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 863us/step - loss: 356421.3438 - accuracy: 0.9928 - val_loss: 4377.6138 - val_accuracy: 0.9935\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 873us/step - loss: 356081.4375 - accuracy: 0.9923 - val_loss: 3305.5259 - val_accuracy: 0.9935\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 357875.6562 - accuracy: 0.9922 - val_loss: 3617.3994 - val_accuracy: 0.9935\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 854us/step - loss: 357043.2500 - accuracy: 0.9923 - val_loss: 2946.6501 - val_accuracy: 0.9935\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 869us/step - loss: 358104.8750 - accuracy: 0.9928 - val_loss: 3289.5833 - val_accuracy: 0.9935\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 960us/step - loss: 356705.9062 - accuracy: 0.9916 - val_loss: 3425.2698 - val_accuracy: 0.9935\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 968us/step - loss: 356256.9375 - accuracy: 0.9913 - val_loss: 3315.5647 - val_accuracy: 0.9935\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356275.1562 - accuracy: 0.9922 - val_loss: 4008.9392 - val_accuracy: 0.9935\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 943us/step - loss: 356892.6250 - accuracy: 0.9928 - val_loss: 4386.1045 - val_accuracy: 0.7159\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 964us/step - loss: 356412.0938 - accuracy: 0.9923 - val_loss: 3298.1541 - val_accuracy: 0.9935\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 978us/step - loss: 357140.0625 - accuracy: 0.9921 - val_loss: 3984.0825 - val_accuracy: 0.9935\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 356804.1875 - accuracy: 0.9923 - val_loss: 3894.4880 - val_accuracy: 0.9935\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 960us/step - loss: 356633.0000 - accuracy: 0.9918 - val_loss: 3310.8982 - val_accuracy: 0.9935\n",
      "Epoch 60/200\n",
      "68/68 [==============================] - 0s 872us/step - loss: 356949.8438 - accuracy: 0.9919 - val_loss: 3379.5093 - val_accuracy: 0.9935\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 862us/step - loss: 356288.3125 - accuracy: 0.9925 - val_loss: 3076.4844 - val_accuracy: 0.9935\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 877us/step - loss: 356480.3125 - accuracy: 0.9927 - val_loss: 3677.5623 - val_accuracy: 0.9935\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 858us/step - loss: 357160.0938 - accuracy: 0.9928 - val_loss: 3630.3389 - val_accuracy: 0.9935\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 863us/step - loss: 356119.1875 - accuracy: 0.9897 - val_loss: 3228.9619 - val_accuracy: 0.9935\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 868us/step - loss: 356500.0000 - accuracy: 0.9901 - val_loss: 3900.4285 - val_accuracy: 0.9935\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 856us/step - loss: 356256.4062 - accuracy: 0.9927 - val_loss: 4324.2788 - val_accuracy: 0.7159\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 871us/step - loss: 356241.3438 - accuracy: 0.9909 - val_loss: 4045.0120 - val_accuracy: 0.9935\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 859us/step - loss: 356627.3125 - accuracy: 0.9923 - val_loss: 3639.9634 - val_accuracy: 0.9935\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 858us/step - loss: 356905.3125 - accuracy: 0.9928 - val_loss: 3747.2605 - val_accuracy: 0.9935\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 856us/step - loss: 357167.8125 - accuracy: 0.9928 - val_loss: 3224.1282 - val_accuracy: 0.9935\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 860us/step - loss: 357025.4375 - accuracy: 0.9925 - val_loss: 4321.9727 - val_accuracy: 0.9935\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 356097.8750 - accuracy: 0.9928 - val_loss: 3197.6860 - val_accuracy: 0.9935\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 854us/step - loss: 356926.1562 - accuracy: 0.9928 - val_loss: 3554.7710 - val_accuracy: 0.9935\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 909us/step - loss: 356419.7812 - accuracy: 0.9928 - val_loss: 3048.6338 - val_accuracy: 0.9935\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 861us/step - loss: 356091.9062 - accuracy: 0.9927 - val_loss: 4539.2500 - val_accuracy: 0.7219\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 889us/step - loss: 356739.3438 - accuracy: 0.9899 - val_loss: 3254.2705 - val_accuracy: 0.9935\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 852us/step - loss: 357269.7500 - accuracy: 0.9916 - val_loss: 4394.5693 - val_accuracy: 0.7159\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 860us/step - loss: 356973.9688 - accuracy: 0.9913 - val_loss: 3677.2239 - val_accuracy: 0.9935\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 355512.3125 - accuracy: 0.9928 - val_loss: 3416.4199 - val_accuracy: 0.9935\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 864us/step - loss: 357230.7500 - accuracy: 0.9921 - val_loss: 3646.6101 - val_accuracy: 0.9935\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 868us/step - loss: 355735.9062 - accuracy: 0.9912 - val_loss: 3814.8059 - val_accuracy: 0.9935\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 872us/step - loss: 355634.8438 - accuracy: 0.9913 - val_loss: 3561.6875 - val_accuracy: 0.9935\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 855us/step - loss: 358309.5312 - accuracy: 0.9908 - val_loss: 3269.3513 - val_accuracy: 0.9935\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 867us/step - loss: 357346.8125 - accuracy: 0.9921 - val_loss: 3084.0066 - val_accuracy: 0.9935\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 874us/step - loss: 357110.3750 - accuracy: 0.9927 - val_loss: 3906.4346 - val_accuracy: 0.9935\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 870us/step - loss: 356262.8125 - accuracy: 0.9920 - val_loss: 3213.9712 - val_accuracy: 0.9935\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 841us/step - loss: 355789.5938 - accuracy: 0.9925 - val_loss: 3219.9963 - val_accuracy: 0.9935\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 871us/step - loss: 355748.7188 - accuracy: 0.9921 - val_loss: 4504.5991 - val_accuracy: 0.7219\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 854us/step - loss: 356927.3750 - accuracy: 0.9915 - val_loss: 4010.2878 - val_accuracy: 0.9935\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 867us/step - loss: 355343.8125 - accuracy: 0.9928 - val_loss: 4013.8042 - val_accuracy: 0.9935\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 855us/step - loss: 355317.4375 - accuracy: 0.9921 - val_loss: 2956.4944 - val_accuracy: 0.9935\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 862us/step - loss: 356433.5938 - accuracy: 0.9928 - val_loss: 3717.6528 - val_accuracy: 0.9935\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 884us/step - loss: 356917.9062 - accuracy: 0.9920 - val_loss: 4355.3447 - val_accuracy: 0.7159\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 889us/step - loss: 357219.9688 - accuracy: 0.9914 - val_loss: 4461.2998 - val_accuracy: 0.7219\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 873us/step - loss: 357031.5000 - accuracy: 0.9925 - val_loss: 3650.2747 - val_accuracy: 0.9935\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 855us/step - loss: 355777.6562 - accuracy: 0.9928 - val_loss: 3394.5671 - val_accuracy: 0.9935\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 892us/step - loss: 356618.1250 - accuracy: 0.9921 - val_loss: 3445.1318 - val_accuracy: 0.9935\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 878us/step - loss: 356427.7812 - accuracy: 0.9923 - val_loss: 3017.5569 - val_accuracy: 0.9935\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 870us/step - loss: 355946.7188 - accuracy: 0.9913 - val_loss: 3233.0920 - val_accuracy: 0.9935\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 930us/step - loss: 355940.5312 - accuracy: 0.9925 - val_loss: 2977.8491 - val_accuracy: 0.9935\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 884us/step - loss: 357216.0938 - accuracy: 0.9918 - val_loss: 4157.7393 - val_accuracy: 0.7159\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 355616.6250 - accuracy: 0.9921 - val_loss: 3346.9612 - val_accuracy: 0.9935\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 854us/step - loss: 357067.2500 - accuracy: 0.9919 - val_loss: 4315.2808 - val_accuracy: 0.7219\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 867us/step - loss: 356335.1250 - accuracy: 0.9916 - val_loss: 3369.6843 - val_accuracy: 0.9935\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 869us/step - loss: 356466.1562 - accuracy: 0.9913 - val_loss: 3922.6262 - val_accuracy: 0.9935\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 890us/step - loss: 355483.4062 - accuracy: 0.9902 - val_loss: 3675.0874 - val_accuracy: 0.9935\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 943us/step - loss: 355814.3438 - accuracy: 0.9912 - val_loss: 2932.5166 - val_accuracy: 0.9935\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 0s 861us/step - loss: 356719.4688 - accuracy: 0.9925 - val_loss: 2953.9697 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 905us/step - loss: 355089.6875 - accuracy: 0.9920 - val_loss: 3062.1533 - val_accuracy: 0.9935\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 917us/step - loss: 356349.2812 - accuracy: 0.9919 - val_loss: 3628.4443 - val_accuracy: 0.9935\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 892us/step - loss: 354878.5312 - accuracy: 0.9928 - val_loss: 3236.9202 - val_accuracy: 0.9935\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 912us/step - loss: 356058.1250 - accuracy: 0.9915 - val_loss: 4272.4316 - val_accuracy: 0.7159\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 878us/step - loss: 356170.1875 - accuracy: 0.9912 - val_loss: 3163.1899 - val_accuracy: 0.9935\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 878us/step - loss: 356491.0625 - accuracy: 0.9920 - val_loss: 4086.5684 - val_accuracy: 0.9935\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 355572.5625 - accuracy: 0.9914 - val_loss: 2929.3948 - val_accuracy: 0.9935\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 893us/step - loss: 356618.7812 - accuracy: 0.9900 - val_loss: 4704.7236 - val_accuracy: 0.6421\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355796.5938 - accuracy: 0.9908 - val_loss: 3760.0112 - val_accuracy: 0.9935\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 354883.3750 - accuracy: 0.9923 - val_loss: 3275.2148 - val_accuracy: 0.9935\n",
      "Epoch 119/200\n",
      "68/68 [==============================] - 0s 971us/step - loss: 356086.9062 - accuracy: 0.9907 - val_loss: 3089.6914 - val_accuracy: 0.9935\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 959us/step - loss: 355872.0312 - accuracy: 0.9919 - val_loss: 4218.8066 - val_accuracy: 0.7159\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 948us/step - loss: 356598.2812 - accuracy: 0.9915 - val_loss: 3469.8264 - val_accuracy: 0.9935\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 957us/step - loss: 355827.7812 - accuracy: 0.9900 - val_loss: 3847.3867 - val_accuracy: 0.9935\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 981us/step - loss: 355813.3750 - accuracy: 0.9920 - val_loss: 3988.9336 - val_accuracy: 0.9935\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 910us/step - loss: 355112.3125 - accuracy: 0.9925 - val_loss: 4514.3271 - val_accuracy: 0.7219\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 870us/step - loss: 355746.8750 - accuracy: 0.9912 - val_loss: 3505.5613 - val_accuracy: 0.9935\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 886us/step - loss: 355586.4062 - accuracy: 0.9928 - val_loss: 4379.6558 - val_accuracy: 0.7159\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 884us/step - loss: 356868.9375 - accuracy: 0.9913 - val_loss: 4257.7324 - val_accuracy: 0.7159\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355432.2188 - accuracy: 0.9920 - val_loss: 3443.0984 - val_accuracy: 0.9935\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356527.9062 - accuracy: 0.9908 - val_loss: 3125.3940 - val_accuracy: 0.9935\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355535.5000 - accuracy: 0.9923 - val_loss: 4189.4697 - val_accuracy: 0.9935\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 893us/step - loss: 354925.9062 - accuracy: 0.9907 - val_loss: 4203.1660 - val_accuracy: 0.9935\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 852us/step - loss: 356734.2812 - accuracy: 0.9923 - val_loss: 3485.3938 - val_accuracy: 0.9935\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 355756.5938 - accuracy: 0.9926 - val_loss: 4049.9397 - val_accuracy: 0.9935\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 879us/step - loss: 355551.0312 - accuracy: 0.9928 - val_loss: 2970.7288 - val_accuracy: 0.9935\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 860us/step - loss: 356603.0312 - accuracy: 0.9919 - val_loss: 3535.1072 - val_accuracy: 0.9935\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 848us/step - loss: 355428.0312 - accuracy: 0.9925 - val_loss: 3474.5591 - val_accuracy: 0.9935\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 901us/step - loss: 355350.5312 - accuracy: 0.9915 - val_loss: 3133.0068 - val_accuracy: 0.9935\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 843us/step - loss: 355820.9688 - accuracy: 0.9900 - val_loss: 2935.3882 - val_accuracy: 0.9935\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 355995.0625 - accuracy: 0.9905 - val_loss: 3236.2654 - val_accuracy: 0.9935\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 881us/step - loss: 355840.9688 - accuracy: 0.9921 - val_loss: 3850.5691 - val_accuracy: 0.9935\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356709.3125 - accuracy: 0.9914 - val_loss: 3925.8755 - val_accuracy: 0.9935\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355319.0625 - accuracy: 0.9919 - val_loss: 2909.2263 - val_accuracy: 0.9935\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 939us/step - loss: 355419.3438 - accuracy: 0.9920 - val_loss: 4070.3472 - val_accuracy: 0.9935\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 862us/step - loss: 357286.3750 - accuracy: 0.9923 - val_loss: 4280.5029 - val_accuracy: 0.7219\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 845us/step - loss: 354970.4688 - accuracy: 0.9900 - val_loss: 3869.0872 - val_accuracy: 0.9935\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 845us/step - loss: 356689.6562 - accuracy: 0.9921 - val_loss: 3807.5374 - val_accuracy: 0.9935\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 856us/step - loss: 355750.8750 - accuracy: 0.9923 - val_loss: 3387.1860 - val_accuracy: 0.9935\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 870us/step - loss: 355762.0000 - accuracy: 0.9916 - val_loss: 3851.8711 - val_accuracy: 0.9935\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356036.5625 - accuracy: 0.9921 - val_loss: 3141.8521 - val_accuracy: 0.9935\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 356104.3125 - accuracy: 0.9914 - val_loss: 2935.1118 - val_accuracy: 0.9935\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 1ms/step - loss: 355621.7188 - accuracy: 0.9914 - val_loss: 3179.4570 - val_accuracy: 0.9935\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 919us/step - loss: 355873.0625 - accuracy: 0.9923 - val_loss: 3331.7327 - val_accuracy: 0.9935\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 852us/step - loss: 354938.2500 - accuracy: 0.9919 - val_loss: 3603.3940 - val_accuracy: 0.9935\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 858us/step - loss: 355728.4688 - accuracy: 0.9928 - val_loss: 2957.2600 - val_accuracy: 0.9935\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 867us/step - loss: 355939.8125 - accuracy: 0.9915 - val_loss: 3853.6487 - val_accuracy: 0.9935\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 862us/step - loss: 355894.3750 - accuracy: 0.9902 - val_loss: 3483.2864 - val_accuracy: 0.9935\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 849us/step - loss: 355736.5625 - accuracy: 0.9928 - val_loss: 2920.0652 - val_accuracy: 0.9935\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 863us/step - loss: 354940.7812 - accuracy: 0.9928 - val_loss: 3497.7515 - val_accuracy: 0.9935\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 847us/step - loss: 356854.1250 - accuracy: 0.9919 - val_loss: 3965.9736 - val_accuracy: 0.9935\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 848us/step - loss: 356097.4375 - accuracy: 0.9909 - val_loss: 3197.1741 - val_accuracy: 0.9935\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 863us/step - loss: 355506.7500 - accuracy: 0.9915 - val_loss: 2940.2329 - val_accuracy: 0.9935\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 897us/step - loss: 355740.0938 - accuracy: 0.9928 - val_loss: 2971.0410 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 866us/step - loss: 355735.7188 - accuracy: 0.9928 - val_loss: 3654.1958 - val_accuracy: 0.9935\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 886us/step - loss: 355884.9062 - accuracy: 0.9897 - val_loss: 2928.6633 - val_accuracy: 0.9935\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 872us/step - loss: 357527.9062 - accuracy: 0.9923 - val_loss: 2935.1106 - val_accuracy: 0.9935\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 864us/step - loss: 355583.4688 - accuracy: 0.9922 - val_loss: 3490.6619 - val_accuracy: 0.9935\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 870us/step - loss: 355771.1875 - accuracy: 0.9911 - val_loss: 5282.7046 - val_accuracy: 0.5320\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 879us/step - loss: 355115.5938 - accuracy: 0.9894 - val_loss: 3496.1667 - val_accuracy: 0.9935\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 877us/step - loss: 356947.5938 - accuracy: 0.9927 - val_loss: 5045.1562 - val_accuracy: 0.5279\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 863us/step - loss: 353700.5625 - accuracy: 0.9904 - val_loss: 3302.7217 - val_accuracy: 0.9935\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 852us/step - loss: 356681.7812 - accuracy: 0.9928 - val_loss: 3374.4099 - val_accuracy: 0.9935\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 850us/step - loss: 355387.0625 - accuracy: 0.9912 - val_loss: 4094.8203 - val_accuracy: 0.9935\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 354932.7188 - accuracy: 0.9920 - val_loss: 5428.2080 - val_accuracy: 0.5167\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 853us/step - loss: 355592.6562 - accuracy: 0.9922 - val_loss: 3831.2029 - val_accuracy: 0.9935\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 854us/step - loss: 355163.6250 - accuracy: 0.9919 - val_loss: 4247.8838 - val_accuracy: 0.9935\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 846us/step - loss: 355974.0625 - accuracy: 0.9927 - val_loss: 3987.0366 - val_accuracy: 0.9935\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 853us/step - loss: 356510.0625 - accuracy: 0.9918 - val_loss: 3902.0283 - val_accuracy: 0.9935\n",
      "Epoch 178/200\n",
      "68/68 [==============================] - 0s 848us/step - loss: 355473.6250 - accuracy: 0.9914 - val_loss: 2973.4563 - val_accuracy: 0.9935\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 864us/step - loss: 355932.9375 - accuracy: 0.9909 - val_loss: 3251.5920 - val_accuracy: 0.9935\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 874us/step - loss: 356208.8750 - accuracy: 0.9928 - val_loss: 2942.5061 - val_accuracy: 0.9935\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 867us/step - loss: 355528.7812 - accuracy: 0.9919 - val_loss: 3116.6511 - val_accuracy: 0.9935\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 862us/step - loss: 354551.8125 - accuracy: 0.9892 - val_loss: 2982.5259 - val_accuracy: 0.9935\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 844us/step - loss: 356279.2188 - accuracy: 0.9921 - val_loss: 3293.1311 - val_accuracy: 0.9935\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 838us/step - loss: 355281.5312 - accuracy: 0.9908 - val_loss: 3390.1743 - val_accuracy: 0.9935\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 845us/step - loss: 354985.0000 - accuracy: 0.9922 - val_loss: 4076.4373 - val_accuracy: 0.9935\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 857us/step - loss: 356532.0625 - accuracy: 0.9922 - val_loss: 3732.9976 - val_accuracy: 0.9935\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 356406.0625 - accuracy: 0.9902 - val_loss: 3657.0347 - val_accuracy: 0.9935\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 847us/step - loss: 356018.4062 - accuracy: 0.9920 - val_loss: 2945.4827 - val_accuracy: 0.9935\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 844us/step - loss: 355982.3438 - accuracy: 0.9919 - val_loss: 2952.9907 - val_accuracy: 0.9935\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 867us/step - loss: 356679.8125 - accuracy: 0.9905 - val_loss: 3871.0715 - val_accuracy: 0.9935\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 894us/step - loss: 355257.3750 - accuracy: 0.9914 - val_loss: 4153.4517 - val_accuracy: 0.9935\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 943us/step - loss: 355925.6562 - accuracy: 0.9913 - val_loss: 3201.1929 - val_accuracy: 0.9935\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 886us/step - loss: 355569.0000 - accuracy: 0.9923 - val_loss: 3012.6343 - val_accuracy: 0.9935\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 881us/step - loss: 355211.2500 - accuracy: 0.9915 - val_loss: 4458.6655 - val_accuracy: 0.7219\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 914us/step - loss: 355493.6875 - accuracy: 0.9919 - val_loss: 4028.1917 - val_accuracy: 0.9935\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 878us/step - loss: 355844.5625 - accuracy: 0.9928 - val_loss: 2946.0339 - val_accuracy: 0.9935\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 873us/step - loss: 355758.4375 - accuracy: 0.9901 - val_loss: 3130.9058 - val_accuracy: 0.9935\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 862us/step - loss: 356338.5312 - accuracy: 0.9908 - val_loss: 4086.5920 - val_accuracy: 0.9935\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 883us/step - loss: 355441.8750 - accuracy: 0.9920 - val_loss: 3609.7839 - val_accuracy: 0.9935\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 859us/step - loss: 355217.1562 - accuracy: 0.9893 - val_loss: 3220.4456 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe8f20e0bd0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,\n",
    "         batch_size=batch_size, epochs=epochs,\n",
    "         verbose=verbose, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 456us/step - loss: 12684.4121 - accuracy: 1.0000\n",
      "Test ACC :  1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test ACC : ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
