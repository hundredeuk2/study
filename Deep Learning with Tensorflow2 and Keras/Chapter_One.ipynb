{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# For my Mac\n",
    "# os.chdir('//Users//patricklee//Desktop//파이썬//DACON//2020DACON_CUP')\n",
    "\n",
    "# For my Desktop\n",
    "os.chdir('C://Users//BIS_COM//data//dacon//2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'./new_train_df.csv', parse_dates=['c_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_time</th>\n",
       "      <th>id</th>\n",
       "      <th>ds_level</th>\n",
       "      <th>country_code</th>\n",
       "      <th>Total visit</th>\n",
       "      <th>browser</th>\n",
       "      <th>platform</th>\n",
       "      <th>Total User</th>\n",
       "      <th>사용자</th>\n",
       "      <th>세션</th>\n",
       "      <th>신규방문자</th>\n",
       "      <th>페이지뷰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-09-09 01:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-09 03:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-09 13:00:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-09-09 18:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-09-09 21:00:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13454</th>\n",
       "      <td>2019-12-30 07:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13455</th>\n",
       "      <td>2019-12-30 08:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>274.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13456</th>\n",
       "      <td>2019-12-30 12:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13457</th>\n",
       "      <td>2019-12-30 15:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13458</th>\n",
       "      <td>2019-12-30 20:00:00</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>658.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13459 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   c_time    id  ds_level  country_code  Total visit  browser  \\\n",
       "0     2018-09-09 01:00:00   1.0       1.0           1.0        -99.0    -99.0   \n",
       "1     2018-09-09 03:00:00   1.0       1.0           1.0        -99.0    -99.0   \n",
       "2     2018-09-09 13:00:00   3.0       1.0           1.0        -99.0    -99.0   \n",
       "3     2018-09-09 18:00:00   1.0       1.0           1.0        -99.0    -99.0   \n",
       "4     2018-09-09 21:00:00   2.0       1.0           1.0        -99.0    -99.0   \n",
       "...                   ...   ...       ...           ...          ...      ...   \n",
       "13454 2019-12-30 07:00:00 -99.0     -99.0         -99.0          1.0      1.0   \n",
       "13455 2019-12-30 08:00:00 -99.0     -99.0         -99.0          7.0      3.0   \n",
       "13456 2019-12-30 12:00:00 -99.0     -99.0         -99.0         16.0      5.0   \n",
       "13457 2019-12-30 15:00:00 -99.0     -99.0         -99.0         36.0      7.0   \n",
       "13458 2019-12-30 20:00:00 -99.0     -99.0         -99.0         18.0      2.0   \n",
       "\n",
       "       platform  Total User    사용자     세션  신규방문자    페이지뷰  \n",
       "0         -99.0       -99.0   20.0   19.0    9.0   259.0  \n",
       "1         -99.0       -99.0   10.0   10.0    2.0   102.0  \n",
       "2         -99.0       -99.0   20.0   16.0    7.0   131.0  \n",
       "3         -99.0       -99.0   13.0   12.0    2.0    47.0  \n",
       "4         -99.0       -99.0   17.0   17.0    7.0   107.0  \n",
       "...         ...         ...    ...    ...    ...     ...  \n",
       "13454       1.0         1.0   12.0   14.0    3.0    72.0  \n",
       "13455       3.0         6.0   29.0   29.0    5.0   274.0  \n",
       "13456       4.0        16.0   58.0   59.0   18.0   624.0  \n",
       "13457       5.0        34.0  100.0  100.0   28.0  1196.0  \n",
       "13458       5.0        16.0   49.0   53.0   16.0   658.0  \n",
       "\n",
       "[13459 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제 첫 번째"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 128\n",
    "verbose = 1\n",
    "nb_classes = 4\n",
    "n_hidden = 128\n",
    "validation_split = 0.2\n",
    "\n",
    "rate = 0.2\n",
    "rate_size = int(len(df) * rate)\n",
    "\n",
    "train = df[:-rate_size]\n",
    "test = df[-rate_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'ds_level', 'country_code', 'Total visit', 'browser', 'platform',\n",
      "       'Total User'],\n",
      "      dtype='object') Index(['사용자', '세션', '신규방문자', '페이지뷰'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "x_col = train.columns[1:8]\n",
    "y_col = train.columns[8:]\n",
    "print(x_col, y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[x_col]\n",
    "Y_train = train[y_col]\n",
    "X_test = test[x_col]\n",
    "Y_test = test[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10768, 7) (2691, 7)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(nb_classes, input_shape=(7,)\n",
    "                            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'SGD',\n",
    "             loss = 'MSE',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 [==============================] - 0s 3ms/step - loss: nan - accuracy: 0.1438 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 983us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 991us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 953us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 983us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 976us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 968us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 983us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 983us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 953us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 968us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 953us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 939us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 953us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 953us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - ETA: 0s - loss: nan - accuracy: 0.007 - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 600us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 631us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 639us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 601us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 582us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 580us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 579us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 601us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 55/200\n",
      "68/68 [==============================] - 0s 601us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 675us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 569us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 565us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 601us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 624us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 599us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 579us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 574us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 565us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 595us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 575us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 178/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 616us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 601us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 631us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 601us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 601us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 580us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 581us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 578us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 579us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 557us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 587us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 572us/step - loss: nan - accuracy: 0.0072 - val_loss: nan - val_accuracy: 0.0065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x282b5a28520>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,\n",
    "         batch_size=batch_size, epochs=epochs,\n",
    "         verbose=verbose, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 317us/step - loss: nan - accuracy: 0.0000e+00\n",
      "Test ACC :  0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test ACC : ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두 번째 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(n_hidden, input_shape=(7,),\n",
    "                            activation='relu'))\n",
    "model.add(keras.layers.Dense(n_hidden,\n",
    "                            activation='relu'))\n",
    "model.add(keras.layers.Dense(nb_classes,\n",
    "                            activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 128)               1024      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 18,052\n",
      "Trainable params: 18,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'SGD',\n",
    "             loss = 'MSE',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 14984252416.0000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 760us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 781us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 734us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 733us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 752us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 760us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 784us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 733us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 730us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 746us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 733us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 744us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 759us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 54/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 777us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 55/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 747us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 60/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.0000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752733.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 755us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 733us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 733us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 754us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 794us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 751us/step - loss: 1752734.1250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752735.0000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 107/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752735.0000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 733us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.1250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 754us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 119/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 747us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 736us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 744us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 744us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 778us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 760us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 733us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 733us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 745us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 755us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 747us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 742us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 731us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 755us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 733us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 749us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.2500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 739us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752735.0000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 741us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 178/200\n",
      "68/68 [==============================] - 0s 737us/step - loss: 1752735.0000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 737us/step - loss: 1752734.7500 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 735us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 794us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 742us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 739us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.1250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 1752735.0000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 1752734.3750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 739us/step - loss: 1752734.5000 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 1752734.6250 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 1752734.8750 - accuracy: 0.0072 - val_loss: 7409.7153 - val_accuracy: 0.0065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x282c1e88970>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,\n",
    "         batch_size=batch_size, epochs=epochs,\n",
    "         verbose=verbose, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 352us/step - loss: 28818.3340 - accuracy: 0.0000e+00\n",
      "Test ACC :  0.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test ACC : ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 세 번째 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(n_hidden, input_shape=(7,),\n",
    "                            activation='relu'))\n",
    "model.add(keras.layers.Dense(n_hidden,\n",
    "                            activation='relu'))\n",
    "model.add(keras.layers.Dense(nb_classes,\n",
    "                            activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               1024      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 18,052\n",
      "Trainable params: 18,052\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'MSE',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 1293443.3750 - accuracy: 0.8968 - val_loss: 4523.7695 - val_accuracy: 0.9935\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 565494.8750 - accuracy: 0.9928 - val_loss: 4736.7231 - val_accuracy: 0.9935\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 549740.5625 - accuracy: 0.9928 - val_loss: 4472.1035 - val_accuracy: 0.9935\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 803us/step - loss: 545801.3750 - accuracy: 0.9928 - val_loss: 4287.3472 - val_accuracy: 0.9935\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 541947.2500 - accuracy: 0.9928 - val_loss: 3733.9385 - val_accuracy: 0.9935\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 822us/step - loss: 538230.8750 - accuracy: 0.9928 - val_loss: 3545.2256 - val_accuracy: 0.9935\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 793us/step - loss: 532010.7500 - accuracy: 0.9928 - val_loss: 3380.4043 - val_accuracy: 0.9935\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 866us/step - loss: 526587.5000 - accuracy: 0.9928 - val_loss: 3618.3894 - val_accuracy: 0.9935\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 520157.3438 - accuracy: 0.9928 - val_loss: 3068.5488 - val_accuracy: 0.9935\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 511979.6250 - accuracy: 0.9928 - val_loss: 3271.2920 - val_accuracy: 0.9935\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 501892.6562 - accuracy: 0.9928 - val_loss: 3289.4878 - val_accuracy: 0.9935\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 490008.0312 - accuracy: 0.9928 - val_loss: 3625.8079 - val_accuracy: 0.9935\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 477118.0000 - accuracy: 0.9928 - val_loss: 3444.2495 - val_accuracy: 0.9935\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 811us/step - loss: 460908.9062 - accuracy: 0.9928 - val_loss: 3306.2266 - val_accuracy: 0.9935\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 835us/step - loss: 445132.5000 - accuracy: 0.9928 - val_loss: 3398.9788 - val_accuracy: 0.9935\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 430279.8438 - accuracy: 0.9928 - val_loss: 3232.9021 - val_accuracy: 0.9935\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 415776.7812 - accuracy: 0.9928 - val_loss: 3403.2639 - val_accuracy: 0.9935\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 818us/step - loss: 403586.0000 - accuracy: 0.9928 - val_loss: 3407.0317 - val_accuracy: 0.9935\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 827us/step - loss: 396458.5625 - accuracy: 0.9919 - val_loss: 2992.1541 - val_accuracy: 0.9935\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 816us/step - loss: 389369.0312 - accuracy: 0.9928 - val_loss: 2967.1477 - val_accuracy: 0.9935\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 383833.4062 - accuracy: 0.9928 - val_loss: 3710.2180 - val_accuracy: 0.9935\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 378013.5000 - accuracy: 0.9928 - val_loss: 2953.4612 - val_accuracy: 0.9935\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 767us/step - loss: 375342.6250 - accuracy: 0.9928 - val_loss: 3247.1462 - val_accuracy: 0.9935\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 876us/step - loss: 370992.2188 - accuracy: 0.9928 - val_loss: 3500.1443 - val_accuracy: 0.9935\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 809us/step - loss: 366736.7500 - accuracy: 0.9928 - val_loss: 3235.9080 - val_accuracy: 0.9935\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 365115.7500 - accuracy: 0.9928 - val_loss: 3602.5229 - val_accuracy: 0.9935\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 364285.6875 - accuracy: 0.9928 - val_loss: 3366.7920 - val_accuracy: 0.9935\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 361732.3438 - accuracy: 0.9928 - val_loss: 2975.2593 - val_accuracy: 0.9935\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 809us/step - loss: 365740.4375 - accuracy: 0.9928 - val_loss: 3313.4290 - val_accuracy: 0.9935\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 817us/step - loss: 358988.1875 - accuracy: 0.9928 - val_loss: 3264.4666 - val_accuracy: 0.9935\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 810us/step - loss: 362226.4062 - accuracy: 0.9928 - val_loss: 3010.1660 - val_accuracy: 0.9935\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 360084.2500 - accuracy: 0.9928 - val_loss: 3460.8164 - val_accuracy: 0.9935\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 358070.6875 - accuracy: 0.9928 - val_loss: 3398.4834 - val_accuracy: 0.9935\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 356386.1875 - accuracy: 0.9928 - val_loss: 3316.4800 - val_accuracy: 0.9935\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 358016.8125 - accuracy: 0.9928 - val_loss: 3279.1074 - val_accuracy: 0.9935\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 357733.6875 - accuracy: 0.9928 - val_loss: 3304.8723 - val_accuracy: 0.9935\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 355862.1250 - accuracy: 0.9928 - val_loss: 3269.3850 - val_accuracy: 0.9935\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 356695.6250 - accuracy: 0.9928 - val_loss: 3652.2490 - val_accuracy: 0.9935\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 355087.8125 - accuracy: 0.9928 - val_loss: 3268.0684 - val_accuracy: 0.9935\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 358982.0000 - accuracy: 0.9928 - val_loss: 3278.9961 - val_accuracy: 0.9935\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 356774.3438 - accuracy: 0.9928 - val_loss: 3405.3860 - val_accuracy: 0.9935\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 357931.2500 - accuracy: 0.9928 - val_loss: 3273.9822 - val_accuracy: 0.9935\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 842us/step - loss: 356407.1562 - accuracy: 0.9928 - val_loss: 3141.2087 - val_accuracy: 0.9935\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 356928.6562 - accuracy: 0.9928 - val_loss: 3273.9072 - val_accuracy: 0.9935\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 355328.0000 - accuracy: 0.9928 - val_loss: 3551.8955 - val_accuracy: 0.9935\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 355487.9688 - accuracy: 0.9928 - val_loss: 3660.0239 - val_accuracy: 0.9935\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 355779.2500 - accuracy: 0.9928 - val_loss: 3516.9070 - val_accuracy: 0.9935\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 829us/step - loss: 355119.9688 - accuracy: 0.9928 - val_loss: 3518.2424 - val_accuracy: 0.9935\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 356153.3125 - accuracy: 0.9928 - val_loss: 3159.6924 - val_accuracy: 0.9935\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 356033.0312 - accuracy: 0.9928 - val_loss: 3335.3647 - val_accuracy: 0.9935\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 355217.2188 - accuracy: 0.9928 - val_loss: 3051.3501 - val_accuracy: 0.9935\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 355129.3125 - accuracy: 0.9928 - val_loss: 3037.7095 - val_accuracy: 0.9935\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 355187.6250 - accuracy: 0.9928 - val_loss: 3467.0056 - val_accuracy: 0.9935\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 356021.7500 - accuracy: 0.9928 - val_loss: 3411.4734 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 356253.7188 - accuracy: 0.9928 - val_loss: 3444.8765 - val_accuracy: 0.9935\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354959.9688 - accuracy: 0.9928 - val_loss: 3188.7100 - val_accuracy: 0.9935\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 835us/step - loss: 355177.2188 - accuracy: 0.9928 - val_loss: 3357.7085 - val_accuracy: 0.9935\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 356404.9688 - accuracy: 0.9928 - val_loss: 3128.1160 - val_accuracy: 0.9935\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 355047.3125 - accuracy: 0.9928 - val_loss: 3221.4050 - val_accuracy: 0.9935\n",
      "Epoch 60/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 360544.8750 - accuracy: 0.9928 - val_loss: 3482.8464 - val_accuracy: 0.9935\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 355172.0000 - accuracy: 0.9928 - val_loss: 3608.9824 - val_accuracy: 0.9935\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 880us/step - loss: 356540.5938 - accuracy: 0.9928 - val_loss: 3534.8386 - val_accuracy: 0.9935\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 356499.0312 - accuracy: 0.9928 - val_loss: 3439.7534 - val_accuracy: 0.9935\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 356177.1562 - accuracy: 0.9928 - val_loss: 3370.5249 - val_accuracy: 0.9935\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 355905.4062 - accuracy: 0.9928 - val_loss: 3347.4998 - val_accuracy: 0.9935\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 355184.2812 - accuracy: 0.9928 - val_loss: 3366.7051 - val_accuracy: 0.9935\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354436.3438 - accuracy: 0.9928 - val_loss: 3262.1580 - val_accuracy: 0.9935\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 358417.1250 - accuracy: 0.9928 - val_loss: 3398.7834 - val_accuracy: 0.9935\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354990.9062 - accuracy: 0.9928 - val_loss: 3305.1438 - val_accuracy: 0.9935\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 353698.5312 - accuracy: 0.9928 - val_loss: 3218.0156 - val_accuracy: 0.9935\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354491.5312 - accuracy: 0.9928 - val_loss: 3296.0767 - val_accuracy: 0.9935\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354245.0625 - accuracy: 0.9928 - val_loss: 3325.5576 - val_accuracy: 0.9935\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353138.2188 - accuracy: 0.9928 - val_loss: 3681.0366 - val_accuracy: 0.9935\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 355187.8750 - accuracy: 0.9928 - val_loss: 3332.1555 - val_accuracy: 0.9935\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354815.1875 - accuracy: 0.9928 - val_loss: 3560.5010 - val_accuracy: 0.9935\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 354547.0000 - accuracy: 0.9928 - val_loss: 3411.7358 - val_accuracy: 0.9935\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353149.2500 - accuracy: 0.9928 - val_loss: 3598.8982 - val_accuracy: 0.9935\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 353927.6875 - accuracy: 0.9928 - val_loss: 3327.1333 - val_accuracy: 0.9935\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353820.8750 - accuracy: 0.9928 - val_loss: 3293.4250 - val_accuracy: 0.9935\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 356651.0938 - accuracy: 0.9928 - val_loss: 3034.2744 - val_accuracy: 0.9935\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354364.8438 - accuracy: 0.9928 - val_loss: 3416.5581 - val_accuracy: 0.9935\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 358436.5000 - accuracy: 0.9928 - val_loss: 3464.7532 - val_accuracy: 0.9935\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353798.7812 - accuracy: 0.9927 - val_loss: 3720.6580 - val_accuracy: 0.9935\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354630.6250 - accuracy: 0.9928 - val_loss: 3793.4788 - val_accuracy: 0.9935\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354119.3438 - accuracy: 0.9928 - val_loss: 3523.1079 - val_accuracy: 0.9935\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 355348.3750 - accuracy: 0.9928 - val_loss: 3226.1897 - val_accuracy: 0.9935\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 355091.7812 - accuracy: 0.9928 - val_loss: 3624.9177 - val_accuracy: 0.9935\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353830.5938 - accuracy: 0.9928 - val_loss: 3299.5886 - val_accuracy: 0.9935\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354767.1562 - accuracy: 0.9928 - val_loss: 3355.5312 - val_accuracy: 0.9935\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 358049.3750 - accuracy: 0.9927 - val_loss: 3295.3164 - val_accuracy: 0.9935\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 357376.3125 - accuracy: 0.9927 - val_loss: 3668.7053 - val_accuracy: 0.9935\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 780us/step - loss: 353732.0625 - accuracy: 0.9928 - val_loss: 3331.4170 - val_accuracy: 0.9935\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353452.2812 - accuracy: 0.9928 - val_loss: 3424.2568 - val_accuracy: 0.9935\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353800.0000 - accuracy: 0.9928 - val_loss: 3393.1487 - val_accuracy: 0.9935\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354338.6250 - accuracy: 0.9926 - val_loss: 3398.3157 - val_accuracy: 0.9935\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 353494.4688 - accuracy: 0.9927 - val_loss: 3107.0564 - val_accuracy: 0.9935\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 817us/step - loss: 355148.7812 - accuracy: 0.9927 - val_loss: 3511.2947 - val_accuracy: 0.9935\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - ETA: 0s - loss: 245132.7188 - accuracy: 0.984 - 0s 794us/step - loss: 352801.4688 - accuracy: 0.9928 - val_loss: 3311.2068 - val_accuracy: 0.9935\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354907.0938 - accuracy: 0.9928 - val_loss: 3244.2505 - val_accuracy: 0.9935\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 806us/step - loss: 355772.5625 - accuracy: 0.9928 - val_loss: 3137.1021 - val_accuracy: 0.9935\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 794us/step - loss: 354935.8750 - accuracy: 0.9928 - val_loss: 3470.5320 - val_accuracy: 0.9935\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354767.1250 - accuracy: 0.9927 - val_loss: 3864.1128 - val_accuracy: 0.9935\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 804us/step - loss: 353950.5938 - accuracy: 0.9928 - val_loss: 3161.4363 - val_accuracy: 0.9935\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353549.4688 - accuracy: 0.9928 - val_loss: 3378.3821 - val_accuracy: 0.9935\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 799us/step - loss: 354934.2500 - accuracy: 0.9928 - val_loss: 3463.5627 - val_accuracy: 0.9935\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 823us/step - loss: 354370.5625 - accuracy: 0.9927 - val_loss: 3452.9453 - val_accuracy: 0.9935\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 805us/step - loss: 352908.3438 - accuracy: 0.9928 - val_loss: 3366.4097 - val_accuracy: 0.9935\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 778us/step - loss: 354231.2188 - accuracy: 0.9927 - val_loss: 3108.7090 - val_accuracy: 0.9935\n",
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354730.7500 - accuracy: 0.9928 - val_loss: 3358.2476 - val_accuracy: 0.9935\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 795us/step - loss: 355516.3438 - accuracy: 0.9928 - val_loss: 3584.7905 - val_accuracy: 0.9935\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 352850.7500 - accuracy: 0.9927 - val_loss: 3377.3689 - val_accuracy: 0.9935\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 803us/step - loss: 354227.0312 - accuracy: 0.9927 - val_loss: 3212.4199 - val_accuracy: 0.9935\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 825us/step - loss: 353338.8125 - accuracy: 0.9928 - val_loss: 3406.8420 - val_accuracy: 0.9935\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 802us/step - loss: 354716.2812 - accuracy: 0.9928 - val_loss: 3525.6582 - val_accuracy: 0.9935\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353754.0938 - accuracy: 0.9928 - val_loss: 3951.4749 - val_accuracy: 0.9935\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 856us/step - loss: 355206.6875 - accuracy: 0.9928 - val_loss: 3394.7715 - val_accuracy: 0.9935\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 888us/step - loss: 354764.7188 - accuracy: 0.9928 - val_loss: 3072.4487 - val_accuracy: 0.9935\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 798us/step - loss: 353433.2812 - accuracy: 0.9928 - val_loss: 3455.0076 - val_accuracy: 0.9935\n",
      "Epoch 119/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353123.1562 - accuracy: 0.9927 - val_loss: 3300.5574 - val_accuracy: 0.9935\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354174.4688 - accuracy: 0.9927 - val_loss: 3484.7305 - val_accuracy: 0.9935\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353344.8125 - accuracy: 0.9927 - val_loss: 3435.1914 - val_accuracy: 0.9935\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 353389.7188 - accuracy: 0.9927 - val_loss: 3462.3113 - val_accuracy: 0.9935\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 355269.1875 - accuracy: 0.9928 - val_loss: 3517.8984 - val_accuracy: 0.9935\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 817us/step - loss: 354208.5312 - accuracy: 0.9928 - val_loss: 3400.8755 - val_accuracy: 0.9935\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 824us/step - loss: 352889.1875 - accuracy: 0.9927 - val_loss: 3552.6001 - val_accuracy: 0.9935\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 808us/step - loss: 353987.0312 - accuracy: 0.9927 - val_loss: 3163.8948 - val_accuracy: 0.9935\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 355670.0312 - accuracy: 0.9927 - val_loss: 3604.7815 - val_accuracy: 0.9935\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353887.3125 - accuracy: 0.9928 - val_loss: 3235.6201 - val_accuracy: 0.9935\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353434.6562 - accuracy: 0.9927 - val_loss: 3559.1433 - val_accuracy: 0.9935\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353198.0312 - accuracy: 0.9928 - val_loss: 3308.6704 - val_accuracy: 0.9935\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353399.1250 - accuracy: 0.9928 - val_loss: 3598.7014 - val_accuracy: 0.9935\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 352958.7812 - accuracy: 0.9927 - val_loss: 3320.3691 - val_accuracy: 0.9935\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353249.8438 - accuracy: 0.9928 - val_loss: 3612.1804 - val_accuracy: 0.9935\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354452.0000 - accuracy: 0.9927 - val_loss: 3552.8740 - val_accuracy: 0.9935\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 352967.6875 - accuracy: 0.9928 - val_loss: 3246.0642 - val_accuracy: 0.9935\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 356170.8750 - accuracy: 0.9927 - val_loss: 3354.8208 - val_accuracy: 0.9935\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 353931.0625 - accuracy: 0.9927 - val_loss: 3015.5496 - val_accuracy: 0.9935\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 355576.4688 - accuracy: 0.9927 - val_loss: 3215.2161 - val_accuracy: 0.9935\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 355141.2812 - accuracy: 0.9927 - val_loss: 3212.6360 - val_accuracy: 0.9935\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 353111.2812 - accuracy: 0.9928 - val_loss: 3508.9495 - val_accuracy: 0.9935\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 356183.2812 - accuracy: 0.9928 - val_loss: 3479.5610 - val_accuracy: 0.9935\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353880.8438 - accuracy: 0.9928 - val_loss: 3460.6013 - val_accuracy: 0.9935\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353952.5625 - accuracy: 0.9927 - val_loss: 3248.8206 - val_accuracy: 0.9935\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354949.4688 - accuracy: 0.9927 - val_loss: 3191.3362 - val_accuracy: 0.9935\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 353661.0625 - accuracy: 0.9927 - val_loss: 3287.0801 - val_accuracy: 0.9935\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 354083.5000 - accuracy: 0.9927 - val_loss: 3659.0278 - val_accuracy: 0.9935\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354097.5312 - accuracy: 0.9926 - val_loss: 3237.4209 - val_accuracy: 0.9935\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 351716.4688 - accuracy: 0.9927 - val_loss: 3490.7568 - val_accuracy: 0.9935\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354187.1250 - accuracy: 0.9927 - val_loss: 3211.0024 - val_accuracy: 0.9935\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354185.4375 - accuracy: 0.9927 - val_loss: 3427.0193 - val_accuracy: 0.9935\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 352856.2812 - accuracy: 0.9927 - val_loss: 3842.7681 - val_accuracy: 0.9935\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353748.0938 - accuracy: 0.9927 - val_loss: 3297.8743 - val_accuracy: 0.9935\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 353228.4688 - accuracy: 0.9928 - val_loss: 3532.2622 - val_accuracy: 0.9935\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 352620.0000 - accuracy: 0.9927 - val_loss: 3468.7205 - val_accuracy: 0.9935\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 355423.2812 - accuracy: 0.9928 - val_loss: 3326.4641 - val_accuracy: 0.9935\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354712.1250 - accuracy: 0.9927 - val_loss: 3823.0637 - val_accuracy: 0.9935\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 355340.5312 - accuracy: 0.9928 - val_loss: 3179.4624 - val_accuracy: 0.9935\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 354536.2812 - accuracy: 0.9928 - val_loss: 3382.7100 - val_accuracy: 0.9935\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 352581.6562 - accuracy: 0.9928 - val_loss: 3703.3276 - val_accuracy: 0.9935\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353463.2812 - accuracy: 0.9927 - val_loss: 3512.4768 - val_accuracy: 0.9935\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 836us/step - loss: 352885.3438 - accuracy: 0.9927 - val_loss: 3223.4968 - val_accuracy: 0.9935\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 352027.9688 - accuracy: 0.9928 - val_loss: 3641.0212 - val_accuracy: 0.9935\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353379.7812 - accuracy: 0.9927 - val_loss: 3555.7512 - val_accuracy: 0.9935\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354484.1250 - accuracy: 0.9928 - val_loss: 3310.0623 - val_accuracy: 0.9935\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354198.2500 - accuracy: 0.9927 - val_loss: 3800.4832 - val_accuracy: 0.9935\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 813us/step - loss: 353567.5938 - accuracy: 0.9928 - val_loss: 3142.6460 - val_accuracy: 0.9935\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 809us/step - loss: 355010.2812 - accuracy: 0.9927 - val_loss: 3450.0261 - val_accuracy: 0.9935\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 805us/step - loss: 352674.3438 - accuracy: 0.9927 - val_loss: 3528.3645 - val_accuracy: 0.9935\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 824us/step - loss: 357056.4062 - accuracy: 0.9927 - val_loss: 3380.2869 - val_accuracy: 0.9935\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 355027.4062 - accuracy: 0.9927 - val_loss: 3315.9270 - val_accuracy: 0.9935\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 352948.2188 - accuracy: 0.9928 - val_loss: 3317.9409 - val_accuracy: 0.9935\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 352290.0000 - accuracy: 0.9927 - val_loss: 3327.5288 - val_accuracy: 0.9935\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 823us/step - loss: 352368.0938 - accuracy: 0.9927 - val_loss: 3219.3899 - val_accuracy: 0.9935\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 790us/step - loss: 355056.4688 - accuracy: 0.9928 - val_loss: 3321.5581 - val_accuracy: 0.9935\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 778us/step - loss: 353179.2812 - accuracy: 0.9927 - val_loss: 3195.7712 - val_accuracy: 0.9935\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354071.1875 - accuracy: 0.9927 - val_loss: 3337.8232 - val_accuracy: 0.9935\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 794us/step - loss: 353068.6875 - accuracy: 0.9928 - val_loss: 3563.0562 - val_accuracy: 0.9935\n",
      "Epoch 178/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354102.9062 - accuracy: 0.9927 - val_loss: 3438.4253 - val_accuracy: 0.9935\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 810us/step - loss: 355916.5938 - accuracy: 0.9928 - val_loss: 3601.6318 - val_accuracy: 0.9935\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 352719.7812 - accuracy: 0.9928 - val_loss: 3487.7976 - val_accuracy: 0.9935\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 806us/step - loss: 352568.2500 - accuracy: 0.9928 - val_loss: 3485.7886 - val_accuracy: 0.9935\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 358590.0625 - accuracy: 0.9928 - val_loss: 3424.2524 - val_accuracy: 0.9935\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 353640.8438 - accuracy: 0.9928 - val_loss: 3484.3931 - val_accuracy: 0.9935\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 800us/step - loss: 355573.8750 - accuracy: 0.9928 - val_loss: 3346.0669 - val_accuracy: 0.9935\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 352658.7500 - accuracy: 0.9928 - val_loss: 3553.9045 - val_accuracy: 0.9935\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 799us/step - loss: 352131.0625 - accuracy: 0.9927 - val_loss: 3990.5840 - val_accuracy: 0.9935\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353319.4688 - accuracy: 0.9927 - val_loss: 3564.3765 - val_accuracy: 0.9935\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 806us/step - loss: 353462.9688 - accuracy: 0.9928 - val_loss: 3558.7615 - val_accuracy: 0.9935\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354617.9375 - accuracy: 0.9927 - val_loss: 3656.5298 - val_accuracy: 0.9935\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 352765.3438 - accuracy: 0.9927 - val_loss: 3603.0916 - val_accuracy: 0.9935\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 811us/step - loss: 352841.8438 - accuracy: 0.9927 - val_loss: 3647.2290 - val_accuracy: 0.9935\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354269.2812 - accuracy: 0.9928 - val_loss: 3464.9109 - val_accuracy: 0.9935\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 804us/step - loss: 353414.2812 - accuracy: 0.9926 - val_loss: 3571.9250 - val_accuracy: 0.9935\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354034.5625 - accuracy: 0.9926 - val_loss: 3703.8013 - val_accuracy: 0.9935\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 811us/step - loss: 352414.0312 - accuracy: 0.9928 - val_loss: 3679.6875 - val_accuracy: 0.9935\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 352325.4688 - accuracy: 0.9927 - val_loss: 3422.1631 - val_accuracy: 0.9935\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353753.1250 - accuracy: 0.9927 - val_loss: 3826.2673 - val_accuracy: 0.9935\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 779us/step - loss: 353259.7188 - accuracy: 0.9928 - val_loss: 3392.0239 - val_accuracy: 0.9935\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 869us/step - loss: 352715.1875 - accuracy: 0.9928 - val_loss: 3398.8198 - val_accuracy: 0.9935\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 802us/step - loss: 352469.5312 - accuracy: 0.9927 - val_loss: 3427.4543 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x282c2264850>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,\n",
    "         batch_size=batch_size, epochs=epochs,\n",
    "         verbose=verbose, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 352us/step - loss: 13468.5752 - accuracy: 1.0000\n",
      "Test ACC :  1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test ACC : ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'RMSProp',\n",
    "             loss = 'MSE',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 [==============================] - 0s 2ms/step - loss: 355380.2812 - accuracy: 0.9927 - val_loss: 3806.3420 - val_accuracy: 0.9935\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354878.3125 - accuracy: 0.9927 - val_loss: 3825.0281 - val_accuracy: 0.9935\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 355049.6250 - accuracy: 0.9927 - val_loss: 3675.4656 - val_accuracy: 0.9935\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354103.2812 - accuracy: 0.9927 - val_loss: 3055.6042 - val_accuracy: 0.9935\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354216.3438 - accuracy: 0.9928 - val_loss: 3894.3372 - val_accuracy: 0.9935\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353955.7500 - accuracy: 0.9927 - val_loss: 3977.2200 - val_accuracy: 0.9935\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354584.3125 - accuracy: 0.9926 - val_loss: 3514.9290 - val_accuracy: 0.9935\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354221.0312 - accuracy: 0.9928 - val_loss: 3310.7678 - val_accuracy: 0.9935\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354972.2188 - accuracy: 0.9928 - val_loss: 3258.3401 - val_accuracy: 0.9935\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 0s 755us/step - loss: 354599.3438 - accuracy: 0.9928 - val_loss: 3717.3352 - val_accuracy: 0.9935\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354501.8750 - accuracy: 0.9928 - val_loss: 3558.5195 - val_accuracy: 0.9935\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 353805.3125 - accuracy: 0.9927 - val_loss: 3100.2666 - val_accuracy: 0.9935\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 355491.5312 - accuracy: 0.9928 - val_loss: 3669.8350 - val_accuracy: 0.9935\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 353109.7812 - accuracy: 0.9928 - val_loss: 3274.5449 - val_accuracy: 0.9935\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353747.1875 - accuracy: 0.9927 - val_loss: 3370.9150 - val_accuracy: 0.9935\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 355267.9688 - accuracy: 0.9928 - val_loss: 3356.7908 - val_accuracy: 0.9935\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354279.1562 - accuracy: 0.9927 - val_loss: 3431.5046 - val_accuracy: 0.9935\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 355306.6250 - accuracy: 0.9927 - val_loss: 3441.6951 - val_accuracy: 0.9935\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 0s 782us/step - loss: 354712.6250 - accuracy: 0.9927 - val_loss: 3611.4644 - val_accuracy: 0.9935\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354773.3750 - accuracy: 0.9928 - val_loss: 3351.4321 - val_accuracy: 0.9935\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354649.1875 - accuracy: 0.9928 - val_loss: 3477.3962 - val_accuracy: 0.9935\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354804.0938 - accuracy: 0.9928 - val_loss: 3932.0125 - val_accuracy: 0.9935\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354628.6875 - accuracy: 0.9927 - val_loss: 4180.9033 - val_accuracy: 0.9935\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354335.2812 - accuracy: 0.9928 - val_loss: 3317.9033 - val_accuracy: 0.9935\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354466.8125 - accuracy: 0.9928 - val_loss: 3277.4988 - val_accuracy: 0.9935\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354193.2812 - accuracy: 0.9927 - val_loss: 3368.6394 - val_accuracy: 0.9935\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354755.3438 - accuracy: 0.9928 - val_loss: 3718.7095 - val_accuracy: 0.9935\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 355315.9688 - accuracy: 0.9928 - val_loss: 3212.4031 - val_accuracy: 0.9935\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354725.1875 - accuracy: 0.9928 - val_loss: 3496.5439 - val_accuracy: 0.9935\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353841.1562 - accuracy: 0.9928 - val_loss: 3524.9897 - val_accuracy: 0.9935\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353912.2812 - accuracy: 0.9927 - val_loss: 3178.8247 - val_accuracy: 0.9935\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 0s 773us/step - loss: 354840.7500 - accuracy: 0.9928 - val_loss: 3926.9192 - val_accuracy: 0.9935\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 354226.4375 - accuracy: 0.9927 - val_loss: 3513.0325 - val_accuracy: 0.9935\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 0s 760us/step - loss: 353653.9375 - accuracy: 0.9927 - val_loss: 3148.8281 - val_accuracy: 0.9935\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 354358.5312 - accuracy: 0.9927 - val_loss: 3392.7795 - val_accuracy: 0.9935\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353919.4688 - accuracy: 0.9926 - val_loss: 3649.0354 - val_accuracy: 0.9935\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353271.8750 - accuracy: 0.9928 - val_loss: 4060.6462 - val_accuracy: 0.9935\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 354332.3750 - accuracy: 0.9927 - val_loss: 3478.2075 - val_accuracy: 0.9935\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 354011.2188 - accuracy: 0.9928 - val_loss: 3398.5986 - val_accuracy: 0.9935\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354327.6250 - accuracy: 0.9928 - val_loss: 3315.4490 - val_accuracy: 0.9935\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 352620.5938 - accuracy: 0.9927 - val_loss: 3455.1296 - val_accuracy: 0.9935\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353964.5938 - accuracy: 0.9927 - val_loss: 4005.9553 - val_accuracy: 0.9935\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 354545.7188 - accuracy: 0.9927 - val_loss: 3262.9792 - val_accuracy: 0.9935\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354133.0312 - accuracy: 0.9928 - val_loss: 3331.0840 - val_accuracy: 0.9935\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353280.5625 - accuracy: 0.9926 - val_loss: 3558.7419 - val_accuracy: 0.9935\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 0s 772us/step - loss: 355240.8438 - accuracy: 0.9928 - val_loss: 2947.5156 - val_accuracy: 0.9935\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354368.8438 - accuracy: 0.9927 - val_loss: 3748.8184 - val_accuracy: 0.9935\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354018.0312 - accuracy: 0.9927 - val_loss: 3582.6960 - val_accuracy: 0.9935\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 355404.1250 - accuracy: 0.9927 - val_loss: 3763.3074 - val_accuracy: 0.9935\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 352863.8125 - accuracy: 0.9927 - val_loss: 3467.0933 - val_accuracy: 0.9935\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 352602.1250 - accuracy: 0.9927 - val_loss: 3356.5515 - val_accuracy: 0.9935\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353374.1250 - accuracy: 0.9928 - val_loss: 3344.7253 - val_accuracy: 0.9935\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 353055.1875 - accuracy: 0.9927 - val_loss: 3320.8447 - val_accuracy: 0.9935\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 352709.0312 - accuracy: 0.9928 - val_loss: 3198.4324 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354050.2500 - accuracy: 0.9928 - val_loss: 3208.2458 - val_accuracy: 0.9935\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 354264.1250 - accuracy: 0.9928 - val_loss: 3538.0977 - val_accuracy: 0.9935\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 0s 865us/step - loss: 354106.9688 - accuracy: 0.9927 - val_loss: 3583.0874 - val_accuracy: 0.9935\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354242.0000 - accuracy: 0.9928 - val_loss: 3469.8796 - val_accuracy: 0.9935\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354659.6562 - accuracy: 0.9928 - val_loss: 3148.9675 - val_accuracy: 0.9935\n",
      "Epoch 60/200\n",
      "68/68 [==============================] - 0s 768us/step - loss: 353967.0000 - accuracy: 0.9927 - val_loss: 3877.1196 - val_accuracy: 0.9935\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353793.8750 - accuracy: 0.9926 - val_loss: 3803.2493 - val_accuracy: 0.9935\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353890.8750 - accuracy: 0.9927 - val_loss: 3836.5325 - val_accuracy: 0.9935\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353932.7188 - accuracy: 0.9928 - val_loss: 3673.7495 - val_accuracy: 0.9935\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353821.7500 - accuracy: 0.9928 - val_loss: 4144.2866 - val_accuracy: 0.9935\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354086.3750 - accuracy: 0.9927 - val_loss: 3207.3772 - val_accuracy: 0.9935\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353830.1250 - accuracy: 0.9927 - val_loss: 3275.1687 - val_accuracy: 0.9935\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 354837.9688 - accuracy: 0.9928 - val_loss: 3980.6426 - val_accuracy: 0.9935\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354085.6875 - accuracy: 0.9927 - val_loss: 4030.3430 - val_accuracy: 0.9935\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353436.2188 - accuracy: 0.9928 - val_loss: 3837.4243 - val_accuracy: 0.9935\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354117.7812 - accuracy: 0.9928 - val_loss: 3273.2244 - val_accuracy: 0.9935\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353724.6875 - accuracy: 0.9928 - val_loss: 3713.0642 - val_accuracy: 0.9935\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353877.1875 - accuracy: 0.9927 - val_loss: 3639.0073 - val_accuracy: 0.9935\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353918.3438 - accuracy: 0.9928 - val_loss: 3286.1130 - val_accuracy: 0.9935\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354222.7500 - accuracy: 0.9928 - val_loss: 4135.3926 - val_accuracy: 0.9935\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354926.2188 - accuracy: 0.9928 - val_loss: 3711.3733 - val_accuracy: 0.9935\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 354162.8438 - accuracy: 0.9928 - val_loss: 3663.8081 - val_accuracy: 0.9935\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 354151.6875 - accuracy: 0.9928 - val_loss: 3422.9419 - val_accuracy: 0.9935\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 353458.4375 - accuracy: 0.9927 - val_loss: 3304.9583 - val_accuracy: 0.9935\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 0s 805us/step - loss: 354131.9688 - accuracy: 0.9927 - val_loss: 3813.6567 - val_accuracy: 0.9935\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353575.5000 - accuracy: 0.9928 - val_loss: 3015.4585 - val_accuracy: 0.9935\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354505.0625 - accuracy: 0.9927 - val_loss: 3038.4702 - val_accuracy: 0.9935\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353522.6875 - accuracy: 0.9928 - val_loss: 4246.9150 - val_accuracy: 0.9935\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 0s 798us/step - loss: 354064.2188 - accuracy: 0.9928 - val_loss: 3407.3035 - val_accuracy: 0.9935\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353953.8750 - accuracy: 0.9927 - val_loss: 3833.5010 - val_accuracy: 0.9935\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 0s 790us/step - loss: 353671.3125 - accuracy: 0.9928 - val_loss: 3660.7334 - val_accuracy: 0.9935\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354164.7812 - accuracy: 0.9928 - val_loss: 3198.0854 - val_accuracy: 0.9935\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 0s 776us/step - loss: 353540.3125 - accuracy: 0.9927 - val_loss: 3423.3171 - val_accuracy: 0.9935\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353723.1562 - accuracy: 0.9927 - val_loss: 3974.9316 - val_accuracy: 0.9935\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 0s 813us/step - loss: 354352.8750 - accuracy: 0.9928 - val_loss: 3423.3623 - val_accuracy: 0.9935\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353782.6250 - accuracy: 0.9928 - val_loss: 2950.4541 - val_accuracy: 0.9935\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 0s 775us/step - loss: 353631.0625 - accuracy: 0.9927 - val_loss: 3061.3347 - val_accuracy: 0.9935\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 354683.2812 - accuracy: 0.9927 - val_loss: 3560.5486 - val_accuracy: 0.9935\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353358.3750 - accuracy: 0.9927 - val_loss: 2949.0339 - val_accuracy: 0.9935\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 0s 793us/step - loss: 354517.0938 - accuracy: 0.9928 - val_loss: 3198.6340 - val_accuracy: 0.9935\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353786.0000 - accuracy: 0.9928 - val_loss: 3090.5068 - val_accuracy: 0.9935\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 0s 802us/step - loss: 352936.6875 - accuracy: 0.9927 - val_loss: 3851.3735 - val_accuracy: 0.9935\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 352953.0938 - accuracy: 0.9928 - val_loss: 3592.3574 - val_accuracy: 0.9935\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 354436.5312 - accuracy: 0.9928 - val_loss: 4036.7759 - val_accuracy: 0.9935\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 354152.5000 - accuracy: 0.9927 - val_loss: 3276.2502 - val_accuracy: 0.9935\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 0s 758us/step - loss: 352940.4688 - accuracy: 0.9928 - val_loss: 3470.3193 - val_accuracy: 0.9935\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 0s 765us/step - loss: 354572.8125 - accuracy: 0.9928 - val_loss: 3164.1826 - val_accuracy: 0.9935\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353486.9375 - accuracy: 0.9928 - val_loss: 3559.4258 - val_accuracy: 0.9935\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 353953.5312 - accuracy: 0.9928 - val_loss: 3343.1738 - val_accuracy: 0.9935\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 353860.3125 - accuracy: 0.9927 - val_loss: 3500.5098 - val_accuracy: 0.9935\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 354583.8125 - accuracy: 0.9927 - val_loss: 3188.4316 - val_accuracy: 0.9935\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 0s 788us/step - loss: 353148.3438 - accuracy: 0.9927 - val_loss: 3122.2739 - val_accuracy: 0.9935\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 0s 826us/step - loss: 352456.9062 - accuracy: 0.9927 - val_loss: 3462.4272 - val_accuracy: 0.9935\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 353101.5938 - accuracy: 0.9927 - val_loss: 2976.9858 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 353061.6562 - accuracy: 0.9928 - val_loss: 3772.5474 - val_accuracy: 0.9935\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353683.4375 - accuracy: 0.9928 - val_loss: 3405.5222 - val_accuracy: 0.9935\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 0s 766us/step - loss: 353145.9062 - accuracy: 0.9928 - val_loss: 4203.0190 - val_accuracy: 0.9935\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 0s 829us/step - loss: 353396.0938 - accuracy: 0.9927 - val_loss: 3737.3879 - val_accuracy: 0.9935\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 0s 909us/step - loss: 353120.1875 - accuracy: 0.9926 - val_loss: 4111.6426 - val_accuracy: 0.9935\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 352941.0625 - accuracy: 0.9927 - val_loss: 3873.3816 - val_accuracy: 0.9935\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 0s 798us/step - loss: 353637.9062 - accuracy: 0.9928 - val_loss: 3720.5818 - val_accuracy: 0.9935\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 353523.5312 - accuracy: 0.9927 - val_loss: 3399.2966 - val_accuracy: 0.9935\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 0s 760us/step - loss: 353661.9688 - accuracy: 0.9927 - val_loss: 3496.3608 - val_accuracy: 0.9935\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353261.9375 - accuracy: 0.9927 - val_loss: 3075.4756 - val_accuracy: 0.9935\n",
      "Epoch 119/200\n",
      "68/68 [==============================] - 0s 752us/step - loss: 353604.3750 - accuracy: 0.9928 - val_loss: 3204.5293 - val_accuracy: 0.9935\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 353515.7188 - accuracy: 0.9927 - val_loss: 3406.6904 - val_accuracy: 0.9935\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 0s 746us/step - loss: 351584.0938 - accuracy: 0.9928 - val_loss: 3572.3130 - val_accuracy: 0.9935\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 354717.2188 - accuracy: 0.9928 - val_loss: 3560.1177 - val_accuracy: 0.9935\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 353477.7500 - accuracy: 0.9927 - val_loss: 4059.3230 - val_accuracy: 0.9935\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 0s 779us/step - loss: 353264.0312 - accuracy: 0.9928 - val_loss: 4034.5278 - val_accuracy: 0.9935\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 0s 831us/step - loss: 352985.0938 - accuracy: 0.9927 - val_loss: 3841.5730 - val_accuracy: 0.9935\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 0s 796us/step - loss: 354006.4375 - accuracy: 0.9928 - val_loss: 3952.7600 - val_accuracy: 0.9935\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 0s 776us/step - loss: 353879.5938 - accuracy: 0.9927 - val_loss: 3045.2339 - val_accuracy: 0.9935\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353922.0312 - accuracy: 0.9928 - val_loss: 3066.3665 - val_accuracy: 0.9935\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 0s 765us/step - loss: 353115.9062 - accuracy: 0.9928 - val_loss: 3236.3140 - val_accuracy: 0.9935\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 0s 809us/step - loss: 353504.2812 - accuracy: 0.9928 - val_loss: 4170.2964 - val_accuracy: 0.9935\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 0s 836us/step - loss: 354679.1250 - accuracy: 0.9927 - val_loss: 2987.1187 - val_accuracy: 0.9935\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 352984.8125 - accuracy: 0.9928 - val_loss: 3518.6729 - val_accuracy: 0.9935\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 354373.6250 - accuracy: 0.9928 - val_loss: 3912.4990 - val_accuracy: 0.9935\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 354982.9688 - accuracy: 0.9927 - val_loss: 3471.4824 - val_accuracy: 0.9935\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 353110.5938 - accuracy: 0.9928 - val_loss: 3344.9939 - val_accuracy: 0.9935\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 0s 765us/step - loss: 353893.8125 - accuracy: 0.9927 - val_loss: 3529.1338 - val_accuracy: 0.9935\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353801.4375 - accuracy: 0.9927 - val_loss: 3125.2900 - val_accuracy: 0.9935\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 0s 743us/step - loss: 353476.8125 - accuracy: 0.9927 - val_loss: 4072.4268 - val_accuracy: 0.9935\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 0s 755us/step - loss: 353381.1250 - accuracy: 0.9926 - val_loss: 3407.6853 - val_accuracy: 0.9935\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 352073.0312 - accuracy: 0.9927 - val_loss: 3210.0044 - val_accuracy: 0.9935\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 0s 760us/step - loss: 352780.6875 - accuracy: 0.9928 - val_loss: 3640.4043 - val_accuracy: 0.9935\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 0s 751us/step - loss: 352732.0625 - accuracy: 0.9928 - val_loss: 3560.5894 - val_accuracy: 0.9935\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 353975.0625 - accuracy: 0.9928 - val_loss: 3700.3962 - val_accuracy: 0.9935\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 353578.0938 - accuracy: 0.9928 - val_loss: 3580.0596 - val_accuracy: 0.9935\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 354066.5000 - accuracy: 0.9928 - val_loss: 3592.9058 - val_accuracy: 0.9935\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 0s 762us/step - loss: 353437.0312 - accuracy: 0.9927 - val_loss: 3642.7358 - val_accuracy: 0.9935\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 352131.4375 - accuracy: 0.9928 - val_loss: 3737.7666 - val_accuracy: 0.9935\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 0s 796us/step - loss: 353376.3125 - accuracy: 0.9927 - val_loss: 3347.5710 - val_accuracy: 0.9935\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 0s 851us/step - loss: 352809.6250 - accuracy: 0.9927 - val_loss: 3739.7085 - val_accuracy: 0.9935\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 353061.2500 - accuracy: 0.9928 - val_loss: 3903.6108 - val_accuracy: 0.9935\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353825.9062 - accuracy: 0.9927 - val_loss: 3704.9458 - val_accuracy: 0.9935\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 0s 767us/step - loss: 353799.4062 - accuracy: 0.9928 - val_loss: 3555.8477 - val_accuracy: 0.9935\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 0s 765us/step - loss: 353426.0312 - accuracy: 0.9928 - val_loss: 4182.3906 - val_accuracy: 0.9935\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353448.0938 - accuracy: 0.9927 - val_loss: 3021.4846 - val_accuracy: 0.9935\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 0s 797us/step - loss: 352761.5938 - accuracy: 0.9927 - val_loss: 3316.9182 - val_accuracy: 0.9935\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 0s 820us/step - loss: 352619.9375 - accuracy: 0.9927 - val_loss: 3058.1780 - val_accuracy: 0.9935\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353211.1562 - accuracy: 0.9928 - val_loss: 3760.9883 - val_accuracy: 0.9935\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 0s 749us/step - loss: 353503.3125 - accuracy: 0.9928 - val_loss: 3522.7937 - val_accuracy: 0.9935\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353487.6250 - accuracy: 0.9928 - val_loss: 3566.7964 - val_accuracy: 0.9935\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 354162.7188 - accuracy: 0.9927 - val_loss: 3763.2473 - val_accuracy: 0.9935\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 352992.5625 - accuracy: 0.9927 - val_loss: 3004.3298 - val_accuracy: 0.9935\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 779us/step - loss: 353446.9062 - accuracy: 0.9926 - val_loss: 2939.2598 - val_accuracy: 0.9935\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 353029.0000 - accuracy: 0.9928 - val_loss: 3172.7227 - val_accuracy: 0.9935\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 0s 822us/step - loss: 352562.3750 - accuracy: 0.9927 - val_loss: 3572.4504 - val_accuracy: 0.9935\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 0s 833us/step - loss: 354050.7188 - accuracy: 0.9928 - val_loss: 3492.6848 - val_accuracy: 0.9935\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 0s 821us/step - loss: 353482.7188 - accuracy: 0.9928 - val_loss: 3180.9297 - val_accuracy: 0.9935\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 0s 798us/step - loss: 353527.8125 - accuracy: 0.9928 - val_loss: 3451.8884 - val_accuracy: 0.9935\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 353482.4375 - accuracy: 0.9928 - val_loss: 4033.1787 - val_accuracy: 0.9935\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 0s 868us/step - loss: 352305.3438 - accuracy: 0.9927 - val_loss: 3504.6938 - val_accuracy: 0.9935\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 0s 850us/step - loss: 352834.1562 - accuracy: 0.9927 - val_loss: 3850.4211 - val_accuracy: 0.9935\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 0s 918us/step - loss: 354117.1250 - accuracy: 0.9928 - val_loss: 3063.6641 - val_accuracy: 0.9935\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 353561.7812 - accuracy: 0.9928 - val_loss: 3704.8027 - val_accuracy: 0.9935\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 0s 809us/step - loss: 352477.3750 - accuracy: 0.9927 - val_loss: 2952.0896 - val_accuracy: 0.9935\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 0s 823us/step - loss: 353943.5000 - accuracy: 0.9927 - val_loss: 3167.3062 - val_accuracy: 0.9935\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 0s 807us/step - loss: 354013.1250 - accuracy: 0.9928 - val_loss: 3446.6438 - val_accuracy: 0.9935\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353621.8750 - accuracy: 0.9928 - val_loss: 3654.6409 - val_accuracy: 0.9935\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353173.0000 - accuracy: 0.9927 - val_loss: 3400.4629 - val_accuracy: 0.9935\n",
      "Epoch 178/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 353580.4062 - accuracy: 0.9927 - val_loss: 2984.7129 - val_accuracy: 0.9935\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 0s 758us/step - loss: 353258.9688 - accuracy: 0.9928 - val_loss: 3688.6494 - val_accuracy: 0.9935\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 353228.9688 - accuracy: 0.9928 - val_loss: 3868.7153 - val_accuracy: 0.9935\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 0s 793us/step - loss: 354537.2500 - accuracy: 0.9928 - val_loss: 4048.3291 - val_accuracy: 0.9935\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 0s 777us/step - loss: 352898.0312 - accuracy: 0.9927 - val_loss: 3487.2957 - val_accuracy: 0.9935\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 0s 810us/step - loss: 352972.6875 - accuracy: 0.9928 - val_loss: 3303.2515 - val_accuracy: 0.9935\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 0s 792us/step - loss: 352840.8438 - accuracy: 0.9927 - val_loss: 3392.2390 - val_accuracy: 0.9935\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 0s 784us/step - loss: 352687.9688 - accuracy: 0.9927 - val_loss: 4049.7466 - val_accuracy: 0.9935\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 353757.8438 - accuracy: 0.9928 - val_loss: 4012.6482 - val_accuracy: 0.9935\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 353859.6250 - accuracy: 0.9927 - val_loss: 3334.4646 - val_accuracy: 0.9935\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 0s 767us/step - loss: 352857.5938 - accuracy: 0.9928 - val_loss: 3182.9834 - val_accuracy: 0.9935\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 0s 765us/step - loss: 353110.1250 - accuracy: 0.9927 - val_loss: 3146.6265 - val_accuracy: 0.9935\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 353368.7500 - accuracy: 0.9927 - val_loss: 3345.6272 - val_accuracy: 0.9935\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 352731.7812 - accuracy: 0.9927 - val_loss: 4020.4846 - val_accuracy: 0.9935\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 0s 758us/step - loss: 353223.5625 - accuracy: 0.9928 - val_loss: 3433.0991 - val_accuracy: 0.9935\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 0s 750us/step - loss: 352115.5625 - accuracy: 0.9928 - val_loss: 3073.7937 - val_accuracy: 0.9935\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353308.5938 - accuracy: 0.9928 - val_loss: 3610.1587 - val_accuracy: 0.9935\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 0s 748us/step - loss: 352218.1562 - accuracy: 0.9927 - val_loss: 3812.6262 - val_accuracy: 0.9935\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 0s 756us/step - loss: 352162.7500 - accuracy: 0.9928 - val_loss: 3444.9119 - val_accuracy: 0.9935\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 0s 770us/step - loss: 353389.3438 - accuracy: 0.9928 - val_loss: 3443.4883 - val_accuracy: 0.9935\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 0s 763us/step - loss: 353747.5000 - accuracy: 0.9928 - val_loss: 3844.4661 - val_accuracy: 0.9935\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 0s 772us/step - loss: 353329.2812 - accuracy: 0.9926 - val_loss: 3742.9958 - val_accuracy: 0.9935\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 0s 764us/step - loss: 353366.6562 - accuracy: 0.9928 - val_loss: 3102.9226 - val_accuracy: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x282bfb8b250>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,\n",
    "         batch_size=batch_size, epochs=epochs,\n",
    "         verbose=verbose, validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85/85 [==============================] - 0s 344us/step - loss: 12195.5234 - accuracy: 1.0000\n",
      "Test ACC :  1.0\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test,Y_test)\n",
    "print('Test ACC : ', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
